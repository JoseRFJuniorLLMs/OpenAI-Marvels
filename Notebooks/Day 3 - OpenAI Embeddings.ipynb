{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Assets/Images/Day 3 Header (Embeddings).png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Day 3\n",
    "\n",
    "Today we will \n",
    "\n",
    "- Learn about Embeddings\n",
    "- Look at available embedding models of OpenAI\n",
    "- Study the embeddings API\n",
    "- Decode the embeddings response object\n",
    "- Apply embeddings to \n",
    "    - Perform Text Search\n",
    "    - Do Text Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief Introduction to Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20px; color: orange\"><b>Embeddings are vector representations of data that capture meaningful relationships between entities</b></span>\n",
    "\n",
    "<span style=\"font-size: 16px; color: blue\"><b>These units are typically words, punctuation marks, or other meaningful substrings that make up the text</b></span>\n",
    "\n",
    "- All Machine Learning/AI models work with numerical data. Before the performance of any operation all text/image/audio/video data has to be transformed into a numerical representation\n",
    "\n",
    "- As a general definition, embeddings are data that has been transformed into n-dimensional matrices for use in deep learning computations.\n",
    "\n",
    "<img src=\"../Assets/Images/Embeddings.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__text-embedding-3-small__\t| $0.02 / 1M tokens\n",
    "\n",
    "__text-embedding-3-large__\t| $0.13 / 1M tokens\n",
    "\n",
    "__ada v2__\t| $0.10 / 1M tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai --quiet #You can remove '--quiet' to see the installation steps\n",
    "%pip install python-dotenv --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Import Libraries ####\n",
    "import openai #OpenAI python library\n",
    "from openai import OpenAI #OpenAI Client\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=client.embeddings.create(\n",
    "  model=\"text-embedding-3-small\",\n",
    "  input=\"The food was delicious\",\n",
    "  encoding_format=\"float\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": [\n",
      "        {\n",
      "            \"embedding\": [\n",
      "                -0.019819789,\n",
      "                -0.021811483,\n",
      "                -0.06169395,\n",
      "                -0.038838044,\n",
      "                0.011288293,\n",
      "                -0.032474335,\n",
      "                -0.007814972,\n",
      "                0.070437975,\n",
      "                -0.008889758,\n",
      "                -0.04471597,\n",
      "                0.020682048,\n",
      "                -0.030701242,\n",
      "                0.005167476,\n",
      "                -0.027980879,\n",
      "                -0.009915967,\n",
      "                -0.009472693,\n",
      "                0.018993964,\n",
      "                -0.021738617,\n",
      "                -0.017390894,\n",
      "                0.023438843,\n",
      "                0.053872906,\n",
      "                -0.0061329617,\n",
      "                -0.023001643,\n",
      "                -0.00004990622,\n",
      "                -0.0068859193,\n",
      "                0.03733213,\n",
      "                -0.00096320896,\n",
      "                -0.0014429159,\n",
      "                -0.009928111,\n",
      "                0.0076753106,\n",
      "                0.017220872,\n",
      "                -0.011616194,\n",
      "                0.023693878,\n",
      "                -0.03424743,\n",
      "                -0.026985032,\n",
      "                -0.022187963,\n",
      "                0.05358144,\n",
      "                0.0347575,\n",
      "                0.034417454,\n",
      "                0.02654783,\n",
      "                0.021520017,\n",
      "                0.060285192,\n",
      "                0.02459257,\n",
      "                0.026474964,\n",
      "                0.049743786,\n",
      "                -0.006090456,\n",
      "                -0.066988945,\n",
      "                0.03235289,\n",
      "                -0.01697798,\n",
      "                -0.0130067365,\n",
      "                -0.012375223,\n",
      "                0.015532788,\n",
      "                -0.0009791485,\n",
      "                0.00421717,\n",
      "                0.0072138202,\n",
      "                -0.0030148667,\n",
      "                -0.009970617,\n",
      "                0.03633628,\n",
      "                0.034660343,\n",
      "                -0.011713349,\n",
      "                0.037696462,\n",
      "                -0.005301065,\n",
      "                0.013492516,\n",
      "                0.016237168,\n",
      "                0.008561857,\n",
      "                -0.0541158,\n",
      "                -0.04933087,\n",
      "                0.008306824,\n",
      "                0.02654783,\n",
      "                0.00553181,\n",
      "                0.0152777545,\n",
      "                0.032765802,\n",
      "                -0.060430925,\n",
      "                -0.043501522,\n",
      "                0.047800668,\n",
      "                -0.007711744,\n",
      "                -0.02014769,\n",
      "                -0.051055387,\n",
      "                0.013589672,\n",
      "                -0.012101973,\n",
      "                -0.042748567,\n",
      "                0.019419022,\n",
      "                -0.014876987,\n",
      "                0.005914361,\n",
      "                0.02212724,\n",
      "                -0.07660737,\n",
      "                -0.036506303,\n",
      "                0.02329311,\n",
      "                -0.011160776,\n",
      "                0.08739167,\n",
      "                0.0002611063,\n",
      "                -0.004954947,\n",
      "                0.03638486,\n",
      "                -0.02283162,\n",
      "                0.040805448,\n",
      "                0.0009290526,\n",
      "                -0.053727172,\n",
      "                0.019637622,\n",
      "                -0.02584345,\n",
      "                0.05052103,\n",
      "                0.0516869,\n",
      "                -0.03215858,\n",
      "                0.0063819233,\n",
      "                -0.011452244,\n",
      "                0.017135859,\n",
      "                0.004384157,\n",
      "                0.058196343,\n",
      "                -0.048383605,\n",
      "                -0.022406563,\n",
      "                -0.025551984,\n",
      "                -0.033154428,\n",
      "                -0.022916632,\n",
      "                -0.015326332,\n",
      "                0.022673741,\n",
      "                0.011087909,\n",
      "                0.040586848,\n",
      "                0.042311363,\n",
      "                -0.10706572,\n",
      "                -0.020694192,\n",
      "                0.02773799,\n",
      "                -0.01746376,\n",
      "                0.013419649,\n",
      "                -0.024398258,\n",
      "                -0.054212954,\n",
      "                -0.027810857,\n",
      "                -0.048286445,\n",
      "                -0.0027203632,\n",
      "                0.02606205,\n",
      "                -0.030895554,\n",
      "                -0.020317713,\n",
      "                0.015678521,\n",
      "                -0.0010451842,\n",
      "                -0.017609494,\n",
      "                -0.014621953,\n",
      "                -0.01689297,\n",
      "                0.011786217,\n",
      "                -0.03657917,\n",
      "                -0.026523542,\n",
      "                -0.017718794,\n",
      "                0.01876322,\n",
      "                0.0060358057,\n",
      "                -0.016419334,\n",
      "                0.04432735,\n",
      "                -0.0037708606,\n",
      "                0.0006466935,\n",
      "                -0.05236699,\n",
      "                -0.06013946,\n",
      "                0.017038703,\n",
      "                0.016856536,\n",
      "                0.025600562,\n",
      "                -0.044643104,\n",
      "                0.014366918,\n",
      "                -0.024155369,\n",
      "                -0.0060024085,\n",
      "                -0.029802551,\n",
      "                -0.0050885365,\n",
      "                0.020803493,\n",
      "                0.0006717415,\n",
      "                0.03310585,\n",
      "                0.01852033,\n",
      "                -0.033470184,\n",
      "                0.010098134,\n",
      "                -0.032280024,\n",
      "                0.0074992157,\n",
      "                -0.0042900373,\n",
      "                0.0017457688,\n",
      "                -0.038449418,\n",
      "                0.03976102,\n",
      "                -0.035680477,\n",
      "                -0.023317399,\n",
      "                -0.03638486,\n",
      "                0.066794634,\n",
      "                0.009065853,\n",
      "                0.013674683,\n",
      "                -0.009065853,\n",
      "                -0.021374283,\n",
      "                0.031187022,\n",
      "                -0.037647884,\n",
      "                -0.00008055205,\n",
      "                -0.026985032,\n",
      "                -0.033008695,\n",
      "                0.062714085,\n",
      "                0.006296912,\n",
      "                0.021605028,\n",
      "                -0.0068677026,\n",
      "                -0.028320923,\n",
      "                -0.00034156346,\n",
      "                -0.009800594,\n",
      "                0.031575646,\n",
      "                0.05377575,\n",
      "                0.039032355,\n",
      "                0.013346782,\n",
      "                -0.0043507596,\n",
      "                -0.07932773,\n",
      "                -0.0021951145,\n",
      "                -0.042214207,\n",
      "                -0.016771525,\n",
      "                0.029001014,\n",
      "                -0.029438216,\n",
      "                0.01887252,\n",
      "                0.049452316,\n",
      "                0.032522913,\n",
      "                0.041339807,\n",
      "                -0.032887246,\n",
      "                0.03142991,\n",
      "                -0.03536472,\n",
      "                -0.025673429,\n",
      "                0.037137818,\n",
      "                -0.0013753622,\n",
      "                -0.027300788,\n",
      "                0.06606597,\n",
      "                -0.00843434,\n",
      "                -0.00902942,\n",
      "                0.016152157,\n",
      "                0.022418708,\n",
      "                0.021058526,\n",
      "                -0.018945387,\n",
      "                -0.007335265,\n",
      "                0.040465403,\n",
      "                0.037793618,\n",
      "                0.0239732,\n",
      "                0.00077572855,\n",
      "                0.08389406,\n",
      "                -0.012290212,\n",
      "                0.00041822548,\n",
      "                0.008525424,\n",
      "                -0.02215153,\n",
      "                -0.0045025656,\n",
      "                0.011519038,\n",
      "                0.019261144,\n",
      "                0.009946328,\n",
      "                0.044885993,\n",
      "                -0.004481313,\n",
      "                0.00015835262,\n",
      "                -0.04675624,\n",
      "                0.02283162,\n",
      "                -0.002841808,\n",
      "                0.03978531,\n",
      "                0.003946956,\n",
      "                0.035656188,\n",
      "                -0.012278068,\n",
      "                -0.026936453,\n",
      "                0.013832562,\n",
      "                0.04214134,\n",
      "                0.014634097,\n",
      "                0.04170414,\n",
      "                -0.0049336944,\n",
      "                -0.013237482,\n",
      "                -0.017913107,\n",
      "                -0.03631199,\n",
      "                0.005401257,\n",
      "                -0.005659327,\n",
      "                0.008476846,\n",
      "                -0.04131552,\n",
      "                -0.0049124416,\n",
      "                -0.004766708,\n",
      "                -0.003275973,\n",
      "                -0.004414518,\n",
      "                0.017184438,\n",
      "                -0.002819037,\n",
      "                -0.046076152,\n",
      "                0.029729683,\n",
      "                0.034393165,\n",
      "                0.02654783,\n",
      "                -0.0028752054,\n",
      "                0.03815795,\n",
      "                -0.004305218,\n",
      "                0.004001606,\n",
      "                -0.0356319,\n",
      "                0.0021723437,\n",
      "                -0.028709548,\n",
      "                -0.027567966,\n",
      "                0.016613647,\n",
      "                0.028102323,\n",
      "                0.0012577126,\n",
      "                0.0020144654,\n",
      "                -0.040708292,\n",
      "                0.030215463,\n",
      "                -0.026742142,\n",
      "                -0.015338477,\n",
      "                -0.018228862,\n",
      "                -0.03895949,\n",
      "                -0.04218992,\n",
      "                -0.040805448,\n",
      "                0.037089236,\n",
      "                -0.0119866,\n",
      "                0.005701833,\n",
      "                -0.01909112,\n",
      "                0.00867723,\n",
      "                -0.009241948,\n",
      "                -0.014403352,\n",
      "                -0.009673078,\n",
      "                0.056301802,\n",
      "                0.002922265,\n",
      "                -0.023572434,\n",
      "                0.036457725,\n",
      "                0.0031423839,\n",
      "                0.012405585,\n",
      "                0.047484912,\n",
      "                0.008920119,\n",
      "                0.030385485,\n",
      "                0.018568909,\n",
      "                -0.010286373,\n",
      "                -0.010887525,\n",
      "                0.0035704768,\n",
      "                0.015010576,\n",
      "                -0.039299533,\n",
      "                0.018447462,\n",
      "                -0.03140562,\n",
      "                0.049719498,\n",
      "                -0.042699985,\n",
      "                0.012363079,\n",
      "                0.044351637,\n",
      "                -0.0316728,\n",
      "                -0.027009321,\n",
      "                -0.038255107,\n",
      "                0.014682675,\n",
      "                0.02399749,\n",
      "                -0.01759735,\n",
      "                -0.02014769,\n",
      "                0.044375926,\n",
      "                -0.010334952,\n",
      "                0.03169709,\n",
      "                0.013868995,\n",
      "                0.024689725,\n",
      "                -0.051832635,\n",
      "                0.054164376,\n",
      "                -0.011743711,\n",
      "                -0.021605028,\n",
      "                -0.00669768,\n",
      "                0.013480372,\n",
      "                -0.0014087595,\n",
      "                0.007833188,\n",
      "                0.039032355,\n",
      "                -0.045056015,\n",
      "                -0.003473321,\n",
      "                0.013711116,\n",
      "                -0.021058526,\n",
      "                0.062956974,\n",
      "                0.030142596,\n",
      "                0.011695133,\n",
      "                -0.030798398,\n",
      "                -0.039882466,\n",
      "                -0.009169081,\n",
      "                0.022904487,\n",
      "                -0.011962311,\n",
      "                0.0435501,\n",
      "                0.04940374,\n",
      "                -0.041096915,\n",
      "                0.04029538,\n",
      "                -0.025551984,\n",
      "                0.0015332404,\n",
      "                -0.0439873,\n",
      "                0.043380078,\n",
      "                -0.005553063,\n",
      "                -0.020269135,\n",
      "                -0.038012218,\n",
      "                0.04867507,\n",
      "                -0.023086654,\n",
      "                0.008695447,\n",
      "                0.00048350205,\n",
      "                0.026960744,\n",
      "                0.055864602,\n",
      "                0.004126087,\n",
      "                0.013249626,\n",
      "                -0.005049067,\n",
      "                -0.0012721341,\n",
      "                -0.0020858143,\n",
      "                -0.017500194,\n",
      "                -0.006491224,\n",
      "                -0.014646241,\n",
      "                -0.0021298379,\n",
      "                -0.037890773,\n",
      "                -0.017099425,\n",
      "                -0.027543677,\n",
      "                0.016115723,\n",
      "                -0.018532474,\n",
      "                0.004484349,\n",
      "                0.0064062127,\n",
      "                0.024313247,\n",
      "                0.040149648,\n",
      "                0.0010451842,\n",
      "                0.0236453,\n",
      "                -0.042699985,\n",
      "                0.025139071,\n",
      "                -0.044594526,\n",
      "                -0.0010937621,\n",
      "                -0.019916944,\n",
      "                0.025697717,\n",
      "                -0.026523542,\n",
      "                0.04029538,\n",
      "                -0.030555509,\n",
      "                -0.026960744,\n",
      "                0.033688784,\n",
      "                -0.0054467986,\n",
      "                0.023876045,\n",
      "                0.01049283,\n",
      "                0.05474731,\n",
      "                0.0040441114,\n",
      "                0.005908289,\n",
      "                0.03655488,\n",
      "                -0.028806703,\n",
      "                -0.024871893,\n",
      "                -0.022309408,\n",
      "                0.009229803,\n",
      "                0.0037587162,\n",
      "                -0.04255425,\n",
      "                -0.016941547,\n",
      "                -0.033154428,\n",
      "                0.037599307,\n",
      "                0.0005677544,\n",
      "                -0.04313719,\n",
      "                0.025916317,\n",
      "                -0.0014239402,\n",
      "                0.010322806,\n",
      "                -0.031818535,\n",
      "                -0.023195954,\n",
      "                -0.0019689237,\n",
      "                0.016795814,\n",
      "                0.026134918,\n",
      "                -0.023001643,\n",
      "                0.011361159,\n",
      "                -0.02538196,\n",
      "                0.0030816614,\n",
      "                -0.008659014,\n",
      "                0.03837655,\n",
      "                0.022357985,\n",
      "                -0.042481385,\n",
      "                -0.01038353,\n",
      "                0.002890386,\n",
      "                -0.020572746,\n",
      "                -0.062422622,\n",
      "                0.024556136,\n",
      "                0.014124028,\n",
      "                -0.012909581,\n",
      "                -0.016516492,\n",
      "                -0.027519388,\n",
      "                0.020232702,\n",
      "                -0.031478487,\n",
      "                -0.037429284,\n",
      "                0.0025442683,\n",
      "                -0.015629943,\n",
      "                -0.011112198,\n",
      "                0.0050126337,\n",
      "                0.020402724,\n",
      "                -0.03733213,\n",
      "                0.03728355,\n",
      "                -0.0018915025,\n",
      "                0.026523542,\n",
      "                0.0078089,\n",
      "                0.01852033,\n",
      "                -0.0060388423,\n",
      "                -0.034684632,\n",
      "                0.009266237,\n",
      "                -0.041558407,\n",
      "                0.024531847,\n",
      "                -0.014682675,\n",
      "                0.0070680864,\n",
      "                -0.018641775,\n",
      "                -0.02985113,\n",
      "                0.0029465542,\n",
      "                0.019528322,\n",
      "                -0.043064322,\n",
      "                -0.019601189,\n",
      "                -0.0037131743,\n",
      "                0.01977121,\n",
      "                0.003725319,\n",
      "                0.060188036,\n",
      "                0.032668646,\n",
      "                -0.02226083,\n",
      "                -0.023657445,\n",
      "                0.028296635,\n",
      "                -0.008057862,\n",
      "                -0.014330485,\n",
      "                -0.012053395,\n",
      "                -0.054795887,\n",
      "                0.028490948,\n",
      "                -0.04189845,\n",
      "                0.0014307714,\n",
      "                -0.021799339,\n",
      "                0.00507032,\n",
      "                0.008525424,\n",
      "                -0.00431129,\n",
      "                0.0019431165,\n",
      "                -0.049282294,\n",
      "                -0.050909653,\n",
      "                0.017828094,\n",
      "                0.011245787,\n",
      "                0.0034854654,\n",
      "                0.0008979324,\n",
      "                0.0038437275,\n",
      "                0.026815008,\n",
      "                -0.012848859,\n",
      "                -0.011154704,\n",
      "                -0.011355087,\n",
      "                -0.0064487183,\n",
      "                -0.042262785,\n",
      "                -0.023475278,\n",
      "                -0.0035947657,\n",
      "                -0.013589672,\n",
      "                -0.009132648,\n",
      "                -0.049986675,\n",
      "                0.021920783,\n",
      "                -0.0036676326,\n",
      "                -0.044813126,\n",
      "                0.0049336944,\n",
      "                -0.04690198,\n",
      "                -0.054650154,\n",
      "                0.01794954,\n",
      "                -0.014974142,\n",
      "                0.017548772,\n",
      "                0.05154117,\n",
      "                -0.013711116,\n",
      "                -0.0057200496,\n",
      "                0.03755073,\n",
      "                0.0479464,\n",
      "                -0.028005168,\n",
      "                0.009393754,\n",
      "                -0.02467758,\n",
      "                0.038813755,\n",
      "                -0.037915062,\n",
      "                -0.031599935,\n",
      "                -0.0012106528,\n",
      "                -0.009770233,\n",
      "                0.018070985,\n",
      "                0.010541407,\n",
      "                0.02337812,\n",
      "                0.022224396,\n",
      "                -0.0016030712,\n",
      "                -0.03378594,\n",
      "                0.01575139,\n",
      "                -0.0015772642,\n",
      "                0.015447777,\n",
      "                -0.004305218,\n",
      "                0.025964895,\n",
      "                -0.013310349,\n",
      "                -0.002362101,\n",
      "                0.016249312,\n",
      "                -0.021022093,\n",
      "                -0.022297263,\n",
      "                0.021216404,\n",
      "                0.008288607,\n",
      "                0.0006144347,\n",
      "                -0.01779166,\n",
      "                0.0158364,\n",
      "                0.025066204,\n",
      "                -0.0016212879,\n",
      "                -0.03711353,\n",
      "                0.022783043,\n",
      "                -0.009169081,\n",
      "                -0.021131393,\n",
      "                -0.020718481,\n",
      "                -0.0024228236,\n",
      "                -0.008197523,\n",
      "                0.02017198,\n",
      "                0.03733213,\n",
      "                -0.007207748,\n",
      "                -0.040902603,\n",
      "                0.00924802,\n",
      "                0.041582696,\n",
      "                -0.016091434,\n",
      "                -0.01816814,\n",
      "                0.001852033,\n",
      "                -0.010863236,\n",
      "                -0.020803493,\n",
      "                0.03402883,\n",
      "                -0.006369779,\n",
      "                0.026985032,\n",
      "                0.036239125,\n",
      "                0.035218988,\n",
      "                0.013783983,\n",
      "                0.045517508,\n",
      "                0.0318914,\n",
      "                -0.054018643,\n",
      "                0.022868054,\n",
      "                0.024337536,\n",
      "                0.08297108,\n",
      "                0.016820103,\n",
      "                -0.00030626857,\n",
      "                0.023438843,\n",
      "                -0.02562485,\n",
      "                0.028490948,\n",
      "                -0.026887875,\n",
      "                0.007062014,\n",
      "                0.02036629,\n",
      "                -0.0012827605,\n",
      "                0.046974845,\n",
      "                0.009928111,\n",
      "                -0.022042228,\n",
      "                -0.03099271,\n",
      "                0.0018277441,\n",
      "                -0.016273601,\n",
      "                0.03912951,\n",
      "                -0.019589044,\n",
      "                0.007262398,\n",
      "                -0.0065155127,\n",
      "                -0.036287703,\n",
      "                0.03655488,\n",
      "                -0.004815286,\n",
      "                0.011840867,\n",
      "                0.008021428,\n",
      "                0.014767686,\n",
      "                0.012678836,\n",
      "                -0.0054376903,\n",
      "                -0.03696779,\n",
      "                0.03235289,\n",
      "                -0.008057862,\n",
      "                -0.0199048,\n",
      "                0.033203006,\n",
      "                -0.013650394,\n",
      "                -0.015047009,\n",
      "                0.000045612953,\n",
      "                0.0022619092,\n",
      "                0.0052373065,\n",
      "                -0.020414868,\n",
      "                -0.01746376,\n",
      "                -0.03419885,\n",
      "                -0.011828722,\n",
      "                -0.0055014486,\n",
      "                -0.022734463,\n",
      "                0.008495063,\n",
      "                0.01667437,\n",
      "                0.009205515,\n",
      "                -0.02795659,\n",
      "                0.0057655913,\n",
      "                0.026596408,\n",
      "                -0.045056015,\n",
      "                0.007857477,\n",
      "                0.014706964,\n",
      "                0.0055044848,\n",
      "                0.027883723,\n",
      "                0.0053587514,\n",
      "                0.021872206,\n",
      "                0.021532161,\n",
      "                -0.024616858,\n",
      "                0.048140712,\n",
      "                0.025503404,\n",
      "                0.017475905,\n",
      "                -0.037356418,\n",
      "                -0.02215153,\n",
      "                -0.010972536,\n",
      "                -0.020451302,\n",
      "                -0.010207434,\n",
      "                0.003679777,\n",
      "                -0.018350307,\n",
      "                0.041874163,\n",
      "                0.034417454,\n",
      "                -0.010322806,\n",
      "                -0.013905428,\n",
      "                -0.025139071,\n",
      "                0.010511046,\n",
      "                -0.048407894,\n",
      "                -0.028976725,\n",
      "                -0.010614274,\n",
      "                -0.0054923403,\n",
      "                0.023827467,\n",
      "                -0.02226083,\n",
      "                -0.010608202,\n",
      "                0.037890773,\n",
      "                -0.018326018,\n",
      "                0.014148317,\n",
      "                -0.014889131,\n",
      "                0.0008235475,\n",
      "                0.03308156,\n",
      "                -0.034636054,\n",
      "                -0.008179306,\n",
      "                -0.013796127,\n",
      "                -0.0032091786,\n",
      "                -0.0076692384,\n",
      "                -0.021192115,\n",
      "                0.047363468,\n",
      "                -0.022248685,\n",
      "                0.023171665,\n",
      "                0.017220872,\n",
      "                0.029073883,\n",
      "                -0.015848545,\n",
      "                0.011045404,\n",
      "                -0.0051219338,\n",
      "                0.043185767,\n",
      "                0.012253779,\n",
      "                -0.030944131,\n",
      "                -0.021629317,\n",
      "                -0.018180285,\n",
      "                0.0056411102,\n",
      "                0.018423174,\n",
      "                -0.07174958,\n",
      "                -0.004660444,\n",
      "                0.01233879,\n",
      "                0.007383843,\n",
      "                0.007632805,\n",
      "                -0.034903232,\n",
      "                0.01711157,\n",
      "                0.020633468,\n",
      "                -0.018678209,\n",
      "                0.03356734,\n",
      "                0.013188904,\n",
      "                0.00083948707,\n",
      "                0.014148317,\n",
      "                -0.0045329267,\n",
      "                -0.083311126,\n",
      "                0.009339104,\n",
      "                -0.024993338,\n",
      "                0.033664495,\n",
      "                -0.026183495,\n",
      "                -0.040028203,\n",
      "                0.015314188,\n",
      "                -0.025236227,\n",
      "                -0.03616626,\n",
      "                0.017439472,\n",
      "                0.020779204,\n",
      "                0.01849604,\n",
      "                0.028539525,\n",
      "                0.00082051137,\n",
      "                0.016467914,\n",
      "                0.0041473396,\n",
      "                0.049258005,\n",
      "                -0.028466659,\n",
      "                -0.0064001405,\n",
      "                0.016528636,\n",
      "                -0.013079603,\n",
      "                0.0024835458,\n",
      "                -0.0050308504,\n",
      "                0.017585205,\n",
      "                -0.046294753,\n",
      "                0.005601641,\n",
      "                0.0021662714,\n",
      "                0.05013241,\n",
      "                0.032110002,\n",
      "                0.031648513,\n",
      "                -0.001218243,\n",
      "                -0.010480685,\n",
      "                -0.040489692,\n",
      "                -0.013711116,\n",
      "                0.017560916,\n",
      "                0.04374441,\n",
      "                -0.006260479,\n",
      "                0.00797285,\n",
      "                -0.011561544,\n",
      "                -0.0156178,\n",
      "                -0.054844465,\n",
      "                -0.0055166297,\n",
      "                -0.018447462,\n",
      "                -0.016249312,\n",
      "                -0.023110943,\n",
      "                0.02014769,\n",
      "                -0.006296912,\n",
      "                0.03174567,\n",
      "                -0.023936767,\n",
      "                -0.030798398,\n",
      "                0.024896182,\n",
      "                -0.04330721,\n",
      "                0.007626733,\n",
      "                0.02456828,\n",
      "                -0.008300751,\n",
      "                0.0274951,\n",
      "                0.02388819,\n",
      "                -0.0008212704,\n",
      "                0.021872206,\n",
      "                0.0015909267,\n",
      "                -0.0038255109,\n",
      "                -0.010796442,\n",
      "                0.012095901,\n",
      "                0.029292483,\n",
      "                -0.024434691,\n",
      "                0.004183773,\n",
      "                0.012605969,\n",
      "                0.021847917,\n",
      "                -0.048820805,\n",
      "                -0.004997453,\n",
      "                0.003045228,\n",
      "                -0.0003557953,\n",
      "                -0.006190648,\n",
      "                0.037429284,\n",
      "                0.020839926,\n",
      "                0.010978608,\n",
      "                0.025527693,\n",
      "                0.0018930206,\n",
      "                0.030191174,\n",
      "                0.00023093485,\n",
      "                0.024373969,\n",
      "                0.024046067,\n",
      "                -0.019370444,\n",
      "                -0.009624499,\n",
      "                -0.024604714,\n",
      "                -0.003321515,\n",
      "                -0.028830992,\n",
      "                0.019977668,\n",
      "                -0.026134918,\n",
      "                -0.02887957,\n",
      "                -0.041412674,\n",
      "                -0.013468226,\n",
      "                -0.031332754,\n",
      "                0.02399749,\n",
      "                -0.00924802,\n",
      "                0.005990264,\n",
      "                0.0026307977,\n",
      "                0.011367232,\n",
      "                -0.018617487,\n",
      "                -0.010073845,\n",
      "                0.008246101,\n",
      "                0.012982448,\n",
      "                -0.013273915,\n",
      "                0.018070985,\n",
      "                0.013213193,\n",
      "                0.047144867,\n",
      "                -0.01686868,\n",
      "                -0.01654078,\n",
      "                0.05732194,\n",
      "                0.025479116,\n",
      "                -0.024604714,\n",
      "                0.0045268545,\n",
      "                -0.021762906,\n",
      "                -0.01328606,\n",
      "                0.0030224572,\n",
      "                0.060236614,\n",
      "                -0.031138442,\n",
      "                0.021568595,\n",
      "                -0.020317713,\n",
      "                -0.0035886934,\n",
      "                0.014148317,\n",
      "                0.020900648,\n",
      "                0.016905114,\n",
      "                -0.005343571,\n",
      "                0.003218287,\n",
      "                -0.033688784,\n",
      "                0.029535372,\n",
      "                0.02985113,\n",
      "                -0.01865392,\n",
      "                -0.010310662,\n",
      "                0.013504661,\n",
      "                0.014706964,\n",
      "                -0.01431834,\n",
      "                -0.024118934,\n",
      "                0.011585833,\n",
      "                0.021216404,\n",
      "                0.024604714,\n",
      "                0.008999059,\n",
      "                -0.00664303,\n",
      "                0.027908012,\n",
      "                -0.028296635,\n",
      "                0.014124028,\n",
      "                -0.005577352,\n",
      "                -0.014026873,\n",
      "                -0.023681734,\n",
      "                -0.01757306,\n",
      "                0.011604049,\n",
      "                0.009132648,\n",
      "                -0.029268194,\n",
      "                -0.021422861,\n",
      "                -0.0036190546,\n",
      "                -0.00019620924,\n",
      "                -0.041436963,\n",
      "                0.0007024822,\n",
      "                0.03636057,\n",
      "                0.022139385,\n",
      "                0.008003212,\n",
      "                0.020621324,\n",
      "                0.0026353518,\n",
      "                0.010171001,\n",
      "                -0.0787448,\n",
      "                -0.04520175,\n",
      "                0.04216563,\n",
      "                0.0072684707,\n",
      "                -0.028150901,\n",
      "                0.014986287,\n",
      "                -0.014379063,\n",
      "                -0.0015393127,\n",
      "                -0.015593511,\n",
      "                0.0011552435,\n",
      "                -0.004007678,\n",
      "                -0.02258873,\n",
      "                -0.036506303,\n",
      "                -0.03657917,\n",
      "                0.0012136889,\n",
      "                0.018848231,\n",
      "                0.025284804,\n",
      "                -0.015581367,\n",
      "                0.0026171352,\n",
      "                0.009509127,\n",
      "                -0.042481385,\n",
      "                0.036190547,\n",
      "                -0.028150901,\n",
      "                -0.041558407,\n",
      "                0.008039645,\n",
      "                -0.0037708606,\n",
      "                0.01570281,\n",
      "                -0.03262007,\n",
      "                0.029948285,\n",
      "                -0.011342943,\n",
      "                0.00012656824,\n",
      "                0.034636054,\n",
      "                -0.0052858843,\n",
      "                -0.004092689,\n",
      "                -0.03006973,\n",
      "                -0.023548145,\n",
      "                -0.024021778,\n",
      "                -0.006570163,\n",
      "                -0.021690039,\n",
      "                0.016480058,\n",
      "                -0.028903859,\n",
      "                -0.011245787,\n",
      "                0.019674055,\n",
      "                -0.009624499,\n",
      "                -0.016795814,\n",
      "                0.03495181,\n",
      "                -0.007086303,\n",
      "                0.00046300824,\n",
      "                -0.01794954,\n",
      "                0.03934811,\n",
      "                -0.018362451,\n",
      "                0.021046381,\n",
      "                -0.024969049,\n",
      "                0.01819243,\n",
      "                -0.0067219688,\n",
      "                -0.035243277,\n",
      "                0.050423875,\n",
      "                0.01363825,\n",
      "                -0.013480372,\n",
      "                -0.040829737,\n",
      "                0.032425757,\n",
      "                0.08044503,\n",
      "                -0.013407504,\n",
      "                0.03798793,\n",
      "                -0.013213193,\n",
      "                -0.016795814,\n",
      "                -0.011682988,\n",
      "                0.013516805,\n",
      "                -0.022139385,\n",
      "                -0.019698344,\n",
      "                -0.009071926,\n",
      "                0.017184438,\n",
      "                -0.024446836,\n",
      "                0.0052919565,\n",
      "                0.013516805,\n",
      "                -0.026620697,\n",
      "                -0.004208062,\n",
      "                0.009928111,\n",
      "                0.014816264,\n",
      "                0.011148632,\n",
      "                -0.038570866,\n",
      "                -0.004894225,\n",
      "                -0.012739558,\n",
      "                -0.029243905,\n",
      "                -0.02445898,\n",
      "                0.022710174,\n",
      "                0.016358612,\n",
      "                0.035437588,\n",
      "                -0.017403038,\n",
      "                0.008695447,\n",
      "                0.017123714,\n",
      "                0.046246175,\n",
      "                -0.016261457,\n",
      "                0.030094018,\n",
      "                -0.0027977843,\n",
      "                -0.021277126,\n",
      "                -0.008531496,\n",
      "                0.0072198925,\n",
      "                -0.013613961,\n",
      "                -0.035121832,\n",
      "                -0.013213193,\n",
      "                -0.04167985,\n",
      "                -0.000596977,\n",
      "                -0.0066308854,\n",
      "                0.008021428,\n",
      "                -0.0022953064,\n",
      "                -0.011883372,\n",
      "                -0.019807644,\n",
      "                0.0433315,\n",
      "                -0.04194703,\n",
      "                0.013067459,\n",
      "                -0.027567966,\n",
      "                -0.02676643,\n",
      "                0.020074824,\n",
      "                0.03330016,\n",
      "                -0.002131356,\n",
      "                0.0105171185,\n",
      "                0.03866802,\n",
      "                -0.01491342,\n",
      "                -0.022892343,\n",
      "                -0.00878653,\n",
      "                -0.013966151,\n",
      "                0.018908953,\n",
      "                0.007717816,\n",
      "                0.019759066,\n",
      "                -0.026985032,\n",
      "                -0.003956064,\n",
      "                0.035510454,\n",
      "                0.013711116,\n",
      "                -0.029389638,\n",
      "                -0.02049988,\n",
      "                0.024859749,\n",
      "                -0.012302357,\n",
      "                -0.008161089,\n",
      "                0.0030103126,\n",
      "                0.021520017,\n",
      "                0.0002396637,\n",
      "                0.0029480723,\n",
      "                0.025114782,\n",
      "                0.013917573,\n",
      "                0.00854364,\n",
      "                -0.03978531,\n",
      "                -0.004447915,\n",
      "                0.041777007,\n",
      "                -0.024228236,\n",
      "                -0.04678053,\n",
      "                -0.004818322,\n",
      "                0.024046067,\n",
      "                0.0056198575,\n",
      "                -0.02399749,\n",
      "                -0.0017655035,\n",
      "                -0.003910522,\n",
      "                -0.00854364,\n",
      "                -0.0097520165,\n",
      "                -0.0018155995,\n",
      "                -0.007887839,\n",
      "                -0.033251584,\n",
      "                -0.022491574,\n",
      "                0.006825197,\n",
      "                0.019030398,\n",
      "                0.009727728,\n",
      "                0.028199479,\n",
      "                -0.009071926,\n",
      "                -0.0060934923,\n",
      "                -0.032522913,\n",
      "                0.016443623,\n",
      "                -0.015532788,\n",
      "                0.02936535,\n",
      "                -0.0048547555,\n",
      "                0.045736108,\n",
      "                -0.03912951,\n",
      "                0.0018930206,\n",
      "                0.005301065,\n",
      "                -0.008701519,\n",
      "                -0.011962311,\n",
      "                0.032547202,\n",
      "                0.031867113,\n",
      "                -0.031624224,\n",
      "                -0.031259887,\n",
      "                -0.058779277,\n",
      "                0.010146712,\n",
      "                -0.020633468,\n",
      "                0.009132648,\n",
      "                0.0034034902,\n",
      "                0.03536472,\n",
      "                0.026450675,\n",
      "                -0.0016167337,\n",
      "                -0.019078976,\n",
      "                0.013261771,\n",
      "                0.018471751,\n",
      "                -0.024155369,\n",
      "                0.019722633,\n",
      "                -0.05732194,\n",
      "                0.01781595,\n",
      "                -0.005158367,\n",
      "                0.012302357,\n",
      "                -0.024337536,\n",
      "                0.03096842,\n",
      "                -0.024629002,\n",
      "                0.038109373,\n",
      "                -0.012618113,\n",
      "                -0.03976102,\n",
      "                0.02036629,\n",
      "                0.013116037,\n",
      "                -0.069806464,\n",
      "                0.013735405,\n",
      "                -0.012223418,\n",
      "                0.015447777,\n",
      "                -0.0077056717,\n",
      "                -0.008416124,\n",
      "                0.030191174,\n",
      "                0.013273915,\n",
      "                0.030118307,\n",
      "                0.010565696,\n",
      "                0.029195327,\n",
      "                -0.040465403,\n",
      "                -0.033275872,\n",
      "                -0.004444879,\n",
      "                -0.015909268,\n",
      "                -0.017609494,\n",
      "                0.008440413,\n",
      "                0.023390265,\n",
      "                0.0048092133,\n",
      "                0.0012660619,\n",
      "                0.040684003,\n",
      "                -0.0038771247,\n",
      "                0.01770665,\n",
      "                -0.020014102,\n",
      "                -0.052949928,\n",
      "                -0.0194676,\n",
      "                -0.009891678,\n",
      "                -0.03609339,\n",
      "                0.028005168,\n",
      "                0.015775679,\n",
      "                0.0018429246,\n",
      "                0.02841808,\n",
      "                0.019916944,\n",
      "                0.0014573374,\n",
      "                0.03636057,\n",
      "                0.006135998,\n",
      "                0.012836714,\n",
      "                0.015217031,\n",
      "                -0.029438216,\n",
      "                0.021459294,\n",
      "                -0.018581053,\n",
      "                0.025211938,\n",
      "                0.025527693,\n",
      "                0.043914434,\n",
      "                0.024386114,\n",
      "                -0.020269135,\n",
      "                -0.010395674,\n",
      "                0.027179344,\n",
      "                0.012618113,\n",
      "                0.01841103,\n",
      "                0.033421606,\n",
      "                0.047387756,\n",
      "                -0.00035181036,\n",
      "                0.002184488,\n",
      "                0.018326018,\n",
      "                -0.021738617,\n",
      "                0.006260479,\n",
      "                -0.02003839,\n",
      "                0.0081914505,\n",
      "                -0.000013994614,\n",
      "                0.008361474,\n",
      "                -0.018447462,\n",
      "                0.0056684352,\n",
      "                -0.020050535,\n",
      "                0.026110629,\n",
      "                -0.055816025,\n",
      "                -0.011355087,\n",
      "                -0.0017154076,\n",
      "                0.013164615,\n",
      "                0.0104624685,\n",
      "                -0.0077603217,\n",
      "                -0.00062468165,\n",
      "                0.005969011,\n",
      "                0.025794873,\n",
      "                -0.022163674,\n",
      "                0.0069952197,\n",
      "                0.026863586,\n",
      "                0.021920783,\n",
      "                -0.004444879,\n",
      "                -0.029875418,\n",
      "                0.022892343,\n",
      "                0.0048669,\n",
      "                -0.03330016,\n",
      "                -0.000760548,\n",
      "                0.09807881,\n",
      "                -0.0063090567,\n",
      "                0.0065337294,\n",
      "                0.02076706,\n",
      "                0.009715583,\n",
      "                -0.012095901,\n",
      "                -0.010073845,\n",
      "                0.005956867,\n",
      "                0.017670216,\n",
      "                -0.0037921134,\n",
      "                0.022734463,\n",
      "                -0.021957217,\n",
      "                0.008877614,\n",
      "                0.0030558545,\n",
      "                0.04216563,\n",
      "                0.022248685,\n",
      "                -0.024762591,\n",
      "                -0.015678521,\n",
      "                0.023681734,\n",
      "                -0.014039017,\n",
      "                0.033470184,\n",
      "                0.031454198,\n",
      "                -0.0011097017,\n",
      "                -0.019273289,\n",
      "                -0.025576273,\n",
      "                0.002741616,\n",
      "                -0.010061701,\n",
      "                -0.04918514,\n",
      "                -0.018641775,\n",
      "                0.030701242,\n",
      "                0.04056256,\n",
      "                -0.007298832,\n",
      "                0.009308743,\n",
      "                0.009667005,\n",
      "                0.022528008,\n",
      "                -0.0102438675,\n",
      "                0.009126576,\n",
      "                -0.008015356,\n",
      "                -0.03281438,\n",
      "                -0.0060266973,\n",
      "                -0.006740186,\n",
      "                0.033397317,\n",
      "                0.0013381698,\n",
      "                0.023038076,\n",
      "                0.015289899,\n",
      "                0.023742456,\n",
      "                0.0012569536,\n",
      "                -0.017500194,\n",
      "                -0.014379063,\n",
      "                -0.011500821,\n",
      "                0.018921098,\n",
      "                -0.022115096,\n",
      "                -0.016589358,\n",
      "                -0.018508185,\n",
      "                -0.020451302,\n",
      "                -0.015034865,\n",
      "                0.014549086,\n",
      "                -0.06407427,\n",
      "                0.00629084,\n",
      "                0.0106264185,\n",
      "                -0.0104624685,\n",
      "                -0.012508813,\n",
      "                0.005877928,\n",
      "                -0.006242262,\n",
      "                0.026110629,\n",
      "                0.013346782,\n",
      "                -0.031454198,\n",
      "                -0.0011605568,\n",
      "                0.020997804,\n",
      "                0.020135546,\n",
      "                0.016807958,\n",
      "                0.021544306,\n",
      "                -0.01008599,\n",
      "                0.00020342002,\n",
      "                0.006169395,\n",
      "                0.011106126,\n",
      "                0.021483583,\n",
      "                -0.0025564127,\n",
      "                -0.010104206,\n",
      "                -0.016067145,\n",
      "                -0.020378435,\n",
      "                0.037162106,\n",
      "                0.023936767,\n",
      "                0.004244495,\n",
      "                -0.0018444427,\n",
      "                -0.019601189,\n",
      "                -0.03281438,\n",
      "                0.010705358,\n",
      "                -0.015994279,\n",
      "                -0.009563777,\n",
      "                0.005911325,\n",
      "                0.021082815,\n",
      "                -0.0006341695,\n",
      "                0.035267565,\n",
      "                0.020196268,\n",
      "                0.03910522,\n",
      "                -0.007924273,\n",
      "                0.014051162,\n",
      "                -0.043598678,\n",
      "                -0.0069648586,\n",
      "                0.015775679,\n",
      "                -0.01570281,\n",
      "                0.0039955336,\n",
      "                0.04235994,\n",
      "                -0.0023028967,\n",
      "                -0.01781595,\n",
      "                -0.03774504,\n",
      "                -0.023936767,\n",
      "                -0.010638563,\n",
      "                -0.04255425,\n",
      "                0.013164615,\n",
      "                -0.006163323,\n",
      "                -0.0072927596,\n",
      "                0.03028833,\n",
      "                0.009521271,\n",
      "                0.024446836,\n",
      "                -0.041995607,\n",
      "                0.005525738,\n",
      "                -0.011573688,\n",
      "                -0.015909268,\n",
      "                0.004751527,\n",
      "                0.011160776,\n",
      "                0.0037860412,\n",
      "                0.026110629,\n",
      "                0.041145492,\n",
      "                -0.015994279,\n",
      "                0.030094018,\n",
      "                0.046877686,\n",
      "                0.025479116,\n",
      "                -0.010268156,\n",
      "                0.013298204,\n",
      "                -0.01838674,\n",
      "                -0.011604049,\n",
      "                -0.015848545,\n",
      "                0.009964544,\n",
      "                -0.004359868,\n",
      "                0.0011544845,\n",
      "                -0.007055942,\n",
      "                0.0033761652,\n",
      "                -0.001471,\n",
      "                -0.011136487,\n",
      "                0.08316539,\n",
      "                -0.031794246,\n",
      "                0.02283162,\n",
      "                0.03281438,\n",
      "                0.004241459,\n",
      "                -0.031332754,\n",
      "                -0.015423488,\n",
      "                0.011597977,\n",
      "                -0.000016093807,\n",
      "                0.0088472525,\n",
      "                0.01570281,\n",
      "                0.014852697,\n",
      "                -0.03351876,\n",
      "                0.020524168,\n",
      "                0.0041078697,\n",
      "                0.046246175,\n",
      "                0.00629084,\n",
      "                0.002210295,\n",
      "                -0.04452166,\n",
      "                0.012861003,\n",
      "                -0.0026520505,\n",
      "                0.013783983,\n",
      "                0.03281438,\n",
      "                0.014391207,\n",
      "                0.02562485,\n",
      "                -0.02226083,\n",
      "                -0.005483232,\n",
      "                -0.021228548,\n",
      "                -0.00074157224,\n",
      "                0.016722947,\n",
      "                -0.022430852,\n",
      "                0.0018110453,\n",
      "                0.0037647884,\n",
      "                -0.010359241,\n",
      "                0.009108359,\n",
      "                -0.03395596,\n",
      "                0.01808313,\n",
      "                0.0030300475,\n",
      "                -0.021252837,\n",
      "                0.006296912,\n",
      "                -0.00006636768,\n",
      "                0.009509127,\n",
      "                -0.017220872,\n",
      "                0.027762279,\n",
      "                -0.016965836,\n",
      "                -0.024046067,\n",
      "                -0.033615917,\n",
      "                -0.033591628,\n",
      "                -0.0148648415,\n",
      "                0.023353832,\n",
      "                0.021058526,\n",
      "                -0.0016440589,\n",
      "                0.017633783,\n",
      "                -0.019406877,\n",
      "                0.052998506,\n",
      "                -0.015071298,\n",
      "                0.03026404,\n",
      "                -0.0056532547,\n",
      "                -0.014634097,\n",
      "                -0.03750215,\n",
      "                -0.005662363,\n",
      "                -0.023936767,\n",
      "                0.029171038,\n",
      "                0.019856222,\n",
      "                0.023110943,\n",
      "                0.0077481773,\n",
      "                -0.0012599897,\n",
      "                0.02039058,\n",
      "                0.0026171352,\n",
      "                -0.010013123,\n",
      "                0.04194703,\n",
      "                -0.03398025,\n",
      "                0.0021283198,\n",
      "                -0.004305218,\n",
      "                0.06494867,\n",
      "                -0.007505288,\n",
      "                0.050472453,\n",
      "                -0.0029161929,\n",
      "                -0.011865156,\n",
      "                -0.0124602355,\n",
      "                -0.012023034,\n",
      "                0.005373932,\n",
      "                -0.038595155,\n",
      "                -0.013031025,\n",
      "                -0.010693214,\n",
      "                0.0023939803,\n",
      "                -0.028102323,\n",
      "                -0.023633156,\n",
      "                -0.0037162104,\n",
      "                0.02586774,\n",
      "                0.018908953,\n",
      "                0.01008599,\n",
      "                -0.046683375,\n",
      "                -0.03334874,\n",
      "                -0.0047545633,\n",
      "                -0.0048577916,\n",
      "                -0.01865392,\n",
      "                0.01030459,\n",
      "                0.0035158265,\n",
      "                -0.029996863,\n",
      "                0.0043720123,\n",
      "                -0.039250955,\n",
      "                0.0059234696,\n",
      "                -0.0055348463,\n",
      "                0.022758754,\n",
      "                -0.015204887,\n",
      "                0.013954006,\n",
      "                -0.009873461,\n",
      "                -0.026474964,\n",
      "                -0.01456123,\n",
      "                -0.008403979,\n",
      "                0.020402724,\n",
      "                -0.003476357,\n",
      "                0.01228414,\n",
      "                -0.0066308854,\n",
      "                -0.00053891126,\n",
      "                -0.0028964581,\n",
      "                -0.028928148,\n",
      "                -0.067669034,\n",
      "                -0.04170414,\n",
      "                0.010213506,\n",
      "                -0.0024228236,\n",
      "                0.03053122,\n",
      "                0.0156178,\n",
      "                0.011215426,\n",
      "                0.01420904,\n",
      "                0.0130067365,\n",
      "                0.010644635,\n",
      "                0.0052980287,\n",
      "                0.007711744,\n",
      "                0.003752644,\n",
      "                0.015678521,\n",
      "                -0.072138205,\n",
      "                -0.031648513,\n",
      "                0.01827744,\n",
      "                0.009618427,\n",
      "                0.0066005243,\n",
      "                0.0197955,\n",
      "                -0.018738931,\n",
      "                -0.024301102,\n",
      "                0.01876322,\n",
      "                0.004390229,\n",
      "                -0.014257618,\n",
      "                0.005425546,\n",
      "                0.0016607575,\n",
      "                0.024920471,\n",
      "                0.0064001405,\n",
      "                -0.032717224,\n",
      "                -0.004872972,\n",
      "                -0.022066519,\n",
      "                -0.0010808586,\n",
      "                -0.0009525826,\n",
      "                -0.009290527,\n",
      "                0.020706337,\n",
      "                0.03395596,\n",
      "                0.037380707,\n",
      "                -0.03976102,\n",
      "                0.017961685,\n",
      "                0.014682675,\n",
      "                -0.01304317,\n",
      "                -0.0037465717,\n",
      "                0.00014051542,\n",
      "                0.02109496,\n",
      "                0.041048337,\n",
      "                0.023365976,\n",
      "                0.0023408483,\n",
      "                0.0041777007,\n",
      "                -0.0014011692,\n",
      "                0.02096137,\n",
      "                0.027810857,\n",
      "                -0.0024698833,\n",
      "                0.03696779,\n",
      "                0.017172294,\n",
      "                -0.015253466,\n",
      "                0.00038843357,\n",
      "                0.0073413374,\n",
      "                0.015520643,\n",
      "                -0.004390229,\n",
      "                0.010504974,\n",
      "                -0.0076753106,\n",
      "                -0.009575921,\n",
      "                -0.026256364,\n",
      "                -0.006321201,\n",
      "                -0.07437279,\n",
      "                0.010474613,\n",
      "                -0.011792289,\n",
      "                0.002258873,\n",
      "                -0.019163987,\n",
      "                0.013103892,\n",
      "                -0.03776933,\n",
      "                -0.030215463,\n",
      "                0.0038619442,\n",
      "                0.026256364,\n",
      "                0.0021647534,\n",
      "                -0.007414204,\n",
      "                -0.024070356,\n",
      "                0.017767372,\n",
      "                -0.0017624674,\n",
      "                -0.024847602,\n",
      "                -0.015654232,\n",
      "                -0.030725531,\n",
      "                0.018131707,\n",
      "                -0.016941547,\n",
      "                0.0019613332,\n",
      "                0.017730938,\n",
      "                -0.011938022,\n",
      "                0.025794873,\n",
      "                0.012739558,\n",
      "                0.012083757,\n",
      "                -0.018836087,\n",
      "                0.0036828131,\n",
      "                -0.0063090567,\n",
      "                0.009333032,\n",
      "                0.018556764,\n",
      "                -0.0089322645,\n",
      "                0.050180987,\n",
      "                -0.055330247,\n",
      "                -0.013358926,\n",
      "                0.01003134,\n",
      "                -0.0045754323,\n",
      "                -0.043282922,\n",
      "                0.012605969,\n",
      "                -0.014658386,\n",
      "                -0.015787823,\n",
      "                0.038643733,\n",
      "                -0.040465403,\n",
      "                0.03704066,\n",
      "                0.012180912,\n",
      "                -0.009478766,\n",
      "                -0.00573523,\n",
      "                0.033275872,\n",
      "                -0.0237546,\n",
      "                -0.008282535,\n",
      "                -0.0033306233,\n",
      "                0.016346468,\n",
      "                -0.046464775,\n",
      "                0.00044251443,\n",
      "                0.019710489,\n",
      "                0.016225023,\n",
      "                0.021835772,\n",
      "                0.038303684,\n",
      "                -0.007814972,\n",
      "                0.022953065,\n",
      "                0.04454595,\n",
      "                0.02215153,\n",
      "                0.017900962,\n",
      "                0.033834517,\n",
      "                -0.016067145\n",
      "            ],\n",
      "            \"index\": 0,\n",
      "            \"object\": \"embedding\"\n",
      "        }\n",
      "    ],\n",
      "    \"model\": \"text-embedding-3-small\",\n",
      "    \"object\": \"list\",\n",
      "    \"usage\": {\n",
      "        \"prompt_tokens\": 4,\n",
      "        \"total_tokens\": 4\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=client.embeddings.create(\n",
    "  model=\"text-embedding-3-small\",\n",
    "  input=[\"The food was delicious\",\"The ambience was nice\",\"The service was ordinary\"],\n",
    "  encoding_format=\"float\",\n",
    "  dimensions=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"data\": [\n",
      "        {\n",
      "            \"embedding\": [\n",
      "                -0.16478635,\n",
      "                -0.18134578,\n",
      "                -0.5129379,\n",
      "                -0.32290855,\n",
      "                0.0938535,\n",
      "                -0.2699992,\n",
      "                -0.0649755,\n",
      "                0.5856378,\n",
      "                -0.073911525,\n",
      "                -0.37177902\n",
      "            ],\n",
      "            \"index\": 0,\n",
      "            \"object\": \"embedding\"\n",
      "        },\n",
      "        {\n",
      "            \"embedding\": [\n",
      "                -0.029102806,\n",
      "                -0.34336767,\n",
      "                -0.66657615,\n",
      "                -0.37806797,\n",
      "                0.08133914,\n",
      "                -0.4815079,\n",
      "                -0.12963039,\n",
      "                0.060725518,\n",
      "                -0.060477655,\n",
      "                -0.17713675\n",
      "            ],\n",
      "            \"index\": 1,\n",
      "            \"object\": \"embedding\"\n",
      "        },\n",
      "        {\n",
      "            \"embedding\": [\n",
      "                -0.27565208,\n",
      "                0.1992017,\n",
      "                -0.5211547,\n",
      "                -0.37973946,\n",
      "                -0.046884183,\n",
      "                -0.20189361,\n",
      "                -0.28731704,\n",
      "                0.56458426,\n",
      "                0.01179956,\n",
      "                0.15532349\n",
      "            ],\n",
      "            \"index\": 2,\n",
      "            \"object\": \"embedding\"\n",
      "        }\n",
      "    ],\n",
      "    \"model\": \"text-embedding-3-small\",\n",
      "    \"object\": \"list\",\n",
      "    \"usage\": {\n",
      "        \"prompt_tokens\": 13,\n",
      "        \"total_tokens\": 13\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_q=client.embeddings.create(\n",
    "  model=\"text-embedding-3-small\",\n",
    "  input=\"food\",\n",
    "  encoding_format=\"float\",\n",
    "  dimensions=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=embeddings_q.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.012315562,\n",
       " -0.16567738,\n",
       " -0.069231726,\n",
       " -0.10728083,\n",
       " 0.4480219,\n",
       " -0.61836094,\n",
       " 0.29532152,\n",
       " 0.4434862,\n",
       " -0.24505134,\n",
       " -0.17046502]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=embeddings.data[0].embedding #\"The food was delicious\"\n",
    "d2=embeddings.data[1].embedding #\"The ambience was nice\"\n",
    "d3=embeddings.data[2].embedding #\"The service was ordinary\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://storage.googleapis.com/lds-media/images/cosine-similarity-vectors.original.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity #for calculating similarities between embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6332542]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([query],[d1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51180575]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([query],[d2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28721449]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([query],[d3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1300+ Towards DataScience Medium Articles Dataset__\n",
    "\n",
    "Data Source - https://www.kaggle.com/datasets/meruvulikith/1300-towards-datascience-medium-articles-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"../Assets/Data/medium.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Beginner’s Guide to Word Embedding with Gens...</td>\n",
       "      <td>1. Introduction of Word2vec\\n\\nWord2vec is one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hands-on Graph Neural Networks with PyTorch &amp; ...</td>\n",
       "      <td>In my last article, I introduced the concept o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to Use ggplot2 in Python</td>\n",
       "      <td>Introduction\\n\\nThanks to its strict implement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Databricks: How to Save Data Frames as CSV Fil...</td>\n",
       "      <td>Photo credit to Mika Baumeister from Unsplash\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Step-by-Step Implementation of Gradient Desc...</td>\n",
       "      <td>A Step-by-Step Implementation of Gradient Desc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  A Beginner’s Guide to Word Embedding with Gens...   \n",
       "1  Hands-on Graph Neural Networks with PyTorch & ...   \n",
       "2                       How to Use ggplot2 in Python   \n",
       "3  Databricks: How to Save Data Frames as CSV Fil...   \n",
       "4  A Step-by-Step Implementation of Gradient Desc...   \n",
       "\n",
       "                                                Text  \n",
       "0  1. Introduction of Word2vec\\n\\nWord2vec is one...  \n",
       "1  In my last article, I introduced the concept o...  \n",
       "2  Introduction\\n\\nThanks to its strict implement...  \n",
       "3  Photo credit to Mika Baumeister from Unsplash\\...  \n",
       "4  A Step-by-Step Implementation of Gradient Desc...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1391, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunc_data=data.iloc[0:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trunc_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/467848919.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  trunc_data['embedding'] = trunc_data.Title.apply(lambda x: get_embedding(x, model='text-embedding-3-small'))\n"
     ]
    }
   ],
   "source": [
    "trunc_data['embedding'] = trunc_data.Title.apply(lambda x: get_embedding(x, model='text-embedding-3-small'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Beginner’s Guide to Word Embedding with Gens...</td>\n",
       "      <td>1. Introduction of Word2vec\\n\\nWord2vec is one...</td>\n",
       "      <td>[-0.024416513741016388, 0.019436374306678772, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hands-on Graph Neural Networks with PyTorch &amp; ...</td>\n",
       "      <td>In my last article, I introduced the concept o...</td>\n",
       "      <td>[-0.011600558646023273, -0.02944890409708023, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to Use ggplot2 in Python</td>\n",
       "      <td>Introduction\\n\\nThanks to its strict implement...</td>\n",
       "      <td>[-0.0054690418764948845, -0.024078190326690674...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Databricks: How to Save Data Frames as CSV Fil...</td>\n",
       "      <td>Photo credit to Mika Baumeister from Unsplash\\...</td>\n",
       "      <td>[-0.003941336181014776, -0.022551342844963074,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Step-by-Step Implementation of Gradient Desc...</td>\n",
       "      <td>A Step-by-Step Implementation of Gradient Desc...</td>\n",
       "      <td>[-0.0020211779046803713, -0.000974284252151846...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  A Beginner’s Guide to Word Embedding with Gens...   \n",
       "1  Hands-on Graph Neural Networks with PyTorch & ...   \n",
       "2                       How to Use ggplot2 in Python   \n",
       "3  Databricks: How to Save Data Frames as CSV Fil...   \n",
       "4  A Step-by-Step Implementation of Gradient Desc...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  1. Introduction of Word2vec\\n\\nWord2vec is one...   \n",
       "1  In my last article, I introduced the concept o...   \n",
       "2  Introduction\\n\\nThanks to its strict implement...   \n",
       "3  Photo credit to Mika Baumeister from Unsplash\\...   \n",
       "4  A Step-by-Step Implementation of Gradient Desc...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.024416513741016388, 0.019436374306678772, ...  \n",
       "1  [-0.011600558646023273, -0.02944890409708023, ...  \n",
       "2  [-0.0054690418764948845, -0.024078190326690674...  \n",
       "3  [-0.003941336181014776, -0.022551342844963074,...  \n",
       "4  [-0.0020211779046803713, -0.000974284252151846...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trunc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_string=\"Deep Learning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_embedding=get_embedding(search_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_37575/1347396313.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n"
     ]
    }
   ],
   "source": [
    "trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>embedding</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Beginner’s Guide to Word Embedding with Gens...</td>\n",
       "      <td>1. Introduction of Word2vec\\n\\nWord2vec is one...</td>\n",
       "      <td>[-0.024416513741016388, 0.019436374306678772, ...</td>\n",
       "      <td>0.300155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hands-on Graph Neural Networks with PyTorch &amp; ...</td>\n",
       "      <td>In my last article, I introduced the concept o...</td>\n",
       "      <td>[-0.011600558646023273, -0.02944890409708023, ...</td>\n",
       "      <td>0.344641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to Use ggplot2 in Python</td>\n",
       "      <td>Introduction\\n\\nThanks to its strict implement...</td>\n",
       "      <td>[-0.0054690418764948845, -0.024078190326690674...</td>\n",
       "      <td>0.109014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Databricks: How to Save Data Frames as CSV Fil...</td>\n",
       "      <td>Photo credit to Mika Baumeister from Unsplash\\...</td>\n",
       "      <td>[-0.003941336181014776, -0.022551342844963074,...</td>\n",
       "      <td>0.169241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Step-by-Step Implementation of Gradient Desc...</td>\n",
       "      <td>A Step-by-Step Implementation of Gradient Desc...</td>\n",
       "      <td>[-0.0020211779046803713, -0.000974284252151846...</td>\n",
       "      <td>0.388754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Data Scientist’s toolkit — How to gather data ...</td>\n",
       "      <td>Data Scientist’s toolkit — How to gather data ...</td>\n",
       "      <td>[-0.026935778558254242, -0.02546488121151924, ...</td>\n",
       "      <td>0.313273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Deep Learning on a Budget</td>\n",
       "      <td>Introduction\\n\\nWhy?\\n\\nThere are many article...</td>\n",
       "      <td>[-0.016848241910338402, -0.045139651745557785,...</td>\n",
       "      <td>0.719206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Generating Startup names with Markov Chains</td>\n",
       "      <td>Generating Startup names with Markov Chains\\n\\...</td>\n",
       "      <td>[0.013092967681586742, -0.0023525876458734274,...</td>\n",
       "      <td>0.165855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>A Recipe for using Open Source Machine Learnin...</td>\n",
       "      <td>A Recipe for using Open Source Machine Learnin...</td>\n",
       "      <td>[-0.017321426421403885, -0.021059678867459297,...</td>\n",
       "      <td>0.387291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>How to Choose Between Multiple Models</td>\n",
       "      <td>How to Choose Between Multiple Models\\n\\nIn a ...</td>\n",
       "      <td>[0.004774938337504864, -0.0009390711784362793,...</td>\n",
       "      <td>0.233194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0   A Beginner’s Guide to Word Embedding with Gens...   \n",
       "1   Hands-on Graph Neural Networks with PyTorch & ...   \n",
       "2                        How to Use ggplot2 in Python   \n",
       "3   Databricks: How to Save Data Frames as CSV Fil...   \n",
       "4   A Step-by-Step Implementation of Gradient Desc...   \n",
       "..                                                ...   \n",
       "95  Data Scientist’s toolkit — How to gather data ...   \n",
       "96                          Deep Learning on a Budget   \n",
       "97        Generating Startup names with Markov Chains   \n",
       "98  A Recipe for using Open Source Machine Learnin...   \n",
       "99              How to Choose Between Multiple Models   \n",
       "\n",
       "                                                 Text  \\\n",
       "0   1. Introduction of Word2vec\\n\\nWord2vec is one...   \n",
       "1   In my last article, I introduced the concept o...   \n",
       "2   Introduction\\n\\nThanks to its strict implement...   \n",
       "3   Photo credit to Mika Baumeister from Unsplash\\...   \n",
       "4   A Step-by-Step Implementation of Gradient Desc...   \n",
       "..                                                ...   \n",
       "95  Data Scientist’s toolkit — How to gather data ...   \n",
       "96  Introduction\\n\\nWhy?\\n\\nThere are many article...   \n",
       "97  Generating Startup names with Markov Chains\\n\\...   \n",
       "98  A Recipe for using Open Source Machine Learnin...   \n",
       "99  How to Choose Between Multiple Models\\n\\nIn a ...   \n",
       "\n",
       "                                            embedding  relevance  \n",
       "0   [-0.024416513741016388, 0.019436374306678772, ...   0.300155  \n",
       "1   [-0.011600558646023273, -0.02944890409708023, ...   0.344641  \n",
       "2   [-0.0054690418764948845, -0.024078190326690674...   0.109014  \n",
       "3   [-0.003941336181014776, -0.022551342844963074,...   0.169241  \n",
       "4   [-0.0020211779046803713, -0.000974284252151846...   0.388754  \n",
       "..                                                ...        ...  \n",
       "95  [-0.026935778558254242, -0.02546488121151924, ...   0.313273  \n",
       "96  [-0.016848241910338402, -0.045139651745557785,...   0.719206  \n",
       "97  [0.013092967681586742, -0.0023525876458734274,...   0.165855  \n",
       "98  [-0.017321426421403885, -0.021059678867459297,...   0.387291  \n",
       "99  [0.004774938337504864, -0.0009390711784362793,...   0.233194  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trunc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>embedding</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Deep Learning on a Budget</td>\n",
       "      <td>Introduction\\n\\nWhy?\\n\\nThere are many article...</td>\n",
       "      <td>[-0.016848241910338402, -0.045139651745557785,...</td>\n",
       "      <td>0.719206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Applied AI: Going From Concept to ML Components</td>\n",
       "      <td>Opening your mind to different ways of applyin...</td>\n",
       "      <td>[-0.016721589490771294, -0.026498831808567047,...</td>\n",
       "      <td>0.482872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Transfer Learning Intuition for Text Classific...</td>\n",
       "      <td>Transfer Learning Intuition for Text Classific...</td>\n",
       "      <td>[-0.022648293524980545, 0.0017097401432693005,...</td>\n",
       "      <td>0.478084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Reinforcement Learning Introduction</td>\n",
       "      <td>Reinforcement Learning Introduction\\n\\nAn intr...</td>\n",
       "      <td>[0.009179973974823952, -0.05973218381404877, 0...</td>\n",
       "      <td>0.470448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Wild Wide AI: responsible data science</td>\n",
       "      <td>Wild Wide AI: responsible data science\\n\\nData...</td>\n",
       "      <td>[0.041022028774023056, -0.00013012583076488227...</td>\n",
       "      <td>0.445177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Why Machine Learning Models Degrade In Production</td>\n",
       "      <td>After several failed ML projects due to unexpe...</td>\n",
       "      <td>[0.012906364165246487, 0.030608268454670906, 0...</td>\n",
       "      <td>0.437601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>An Introduction to Recurrent Neural Networks f...</td>\n",
       "      <td>An Introduction to Recurrent Neural Networks f...</td>\n",
       "      <td>[-0.01791239343583584, -0.02631079964339733, 0...</td>\n",
       "      <td>0.424425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What if AI model understanding were easy?</td>\n",
       "      <td>Irreverent Demystifiers\\n\\nWhat if AI model un...</td>\n",
       "      <td>[-0.011677316389977932, -0.0018296980997547507...</td>\n",
       "      <td>0.422850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Getting Started with Google BigQuery’s Machine...</td>\n",
       "      <td>While still in Beta, BigQuery ML has been avai...</td>\n",
       "      <td>[-0.03437798097729683, 0.012720847502350807, 0...</td>\n",
       "      <td>0.416430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Review: DeepPose — Cascade of CNN (Human Pose ...</td>\n",
       "      <td>Review: DeepPose — Cascade of CNN (Human Pose ...</td>\n",
       "      <td>[0.01773509941995144, -0.03974172845482826, 0....</td>\n",
       "      <td>0.412199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "96                          Deep Learning on a Budget   \n",
       "79    Applied AI: Going From Concept to ML Components   \n",
       "73  Transfer Learning Intuition for Text Classific...   \n",
       "54                Reinforcement Learning Introduction   \n",
       "80             Wild Wide AI: responsible data science   \n",
       "26  Why Machine Learning Models Degrade In Production   \n",
       "29  An Introduction to Recurrent Neural Networks f...   \n",
       "9           What if AI model understanding were easy?   \n",
       "68  Getting Started with Google BigQuery’s Machine...   \n",
       "69  Review: DeepPose — Cascade of CNN (Human Pose ...   \n",
       "\n",
       "                                                 Text  \\\n",
       "96  Introduction\\n\\nWhy?\\n\\nThere are many article...   \n",
       "79  Opening your mind to different ways of applyin...   \n",
       "73  Transfer Learning Intuition for Text Classific...   \n",
       "54  Reinforcement Learning Introduction\\n\\nAn intr...   \n",
       "80  Wild Wide AI: responsible data science\\n\\nData...   \n",
       "26  After several failed ML projects due to unexpe...   \n",
       "29  An Introduction to Recurrent Neural Networks f...   \n",
       "9   Irreverent Demystifiers\\n\\nWhat if AI model un...   \n",
       "68  While still in Beta, BigQuery ML has been avai...   \n",
       "69  Review: DeepPose — Cascade of CNN (Human Pose ...   \n",
       "\n",
       "                                            embedding  relevance  \n",
       "96  [-0.016848241910338402, -0.045139651745557785,...   0.719206  \n",
       "79  [-0.016721589490771294, -0.026498831808567047,...   0.482872  \n",
       "73  [-0.022648293524980545, 0.0017097401432693005,...   0.478084  \n",
       "54  [0.009179973974823952, -0.05973218381404877, 0...   0.470448  \n",
       "80  [0.041022028774023056, -0.00013012583076488227...   0.445177  \n",
       "26  [0.012906364165246487, 0.030608268454670906, 0...   0.437601  \n",
       "29  [-0.01791239343583584, -0.02631079964339733, 0...   0.424425  \n",
       "9   [-0.011677316389977932, -0.0018296980997547507...   0.422850  \n",
       "68  [-0.03437798097729683, 0.012720847502350807, 0...   0.416430  \n",
       "69  [0.01773509941995144, -0.03974172845482826, 0....   0.412199  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trunc_data.sort_values(by=\"relevance\",ascending=False).iloc[0:10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! We're at the end of Day 3!\n",
    "\n",
    "Hopefully, now we are fairly confident around using OpenAI embeddings. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Assets/Images/profile.png\" width=50> \n",
    "\n",
    "Hi! I'm Abhinav! A data science and AI professional with over 15 years in the industry. Passionate about AI advancements, I constantly explore emerging technologies to push the boundaries and create positive impacts in the world. Let’s build the future, together!\n",
    "\n",
    "<span style=\"font-size: 20px; color: orange\"><b>Connect with me!</b></span>\n",
    "\n",
    "\n",
    " \n",
    "[![GitHub followers](https://img.shields.io/github/followers/abhinav-kimothi?label=Follow&style=social)](https://github.com/abhinav-kimothi)\n",
    "[![Me](https://img.shields.io/badge/Medium-8A2BE2)](https://medium.com/@abhinavkimothi)\n",
    "[![LIn](https://img.shields.io/badge/LinkedIn-blue)](https://www.linkedin.com/in/abhinav-kimothi/)\n",
    "[![Mail](https://img.shields.io/badge/eMail-green)](mailto:abhinav.kimothi.ds@gmail.com)\n",
    "[![Twitter Follow](https://img.shields.io/twitter/follow/@?style=social)](https://twitter.com/abhinav_kimothi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20px; color: orange\"><b>Also, read my ebooks for more on Generative AI!</b></span>\n",
    "\n",
    "\n",
    "\n",
    "<a href=\"https://abhinavkimothi.gumroad.com/l/GenAILLM\">\n",
    "    <img src=\"https://public-files.gumroad.com/jsdnnne2gnhu61f6hrdprwx2255i\" width=150>\n",
    "</a><a href=\"abhinavkimothi.gumroad.com/l/RAG\">\n",
    "    <img src=\"https://public-files.gumroad.com/v17k9tp2fnbbtg8iwoxt4m3xgivq\" width=150>\n",
    "</a><a href=\"abhinavkimothi.gumroad.com/l/GenAITaxonomy\">\n",
    "    <img src=\"https://public-files.gumroad.com/a730ysxb7a928bb5xkz6fuqabaqp\" width=150>\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Assets/Images/That’s all for the day!.png\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
