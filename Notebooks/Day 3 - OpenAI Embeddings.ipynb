{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Assets/Images/Day 3 Header (Embeddings).png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Day 3\n",
    "\n",
    "Today we will \n",
    "\n",
    "- Learn about Embeddings\n",
    "- Look at available embedding models of OpenAI\n",
    "- Study the embeddings API\n",
    "- Decode the embeddings response object\n",
    "- Apply embeddings to \n",
    "    - Perform Text Search\n",
    "    - Do Text Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief Introduction to Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 20px; color: orange\"><b>Embeddings are vector representations of data that capture meaningful relationships between entities</b></span>\n",
    "\n",
    "<span style=\"font-size: 16px; color: blue\"><b>These units are typically words, punctuation marks, or other meaningful substrings that make up the text</b></span>\n",
    "\n",
    "- All Machine Learning/AI models work with numerical data. Before the performance of any operation all text/image/audio/video data has to be transformed into a numerical representation\n",
    "\n",
    "- As a general definition, embeddings are data that has been transformed into n-dimensional matrices for use in deep learning computations.\n",
    "\n",
    "<img src=\"../Assets/Images/Embeddings.png\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Available OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__text-embedding-3-small__\t| $0.02 / 1M tokens\n",
    "\n",
    "__text-embedding-3-large__\t| $0.13 / 1M tokens\n",
    "\n",
    "__ada v2__\t| $0.10 / 1M tokens\n",
    "\n",
    "<span style=\"font-size: 14px; color: orange\">__IMP__ : __\"model\"__ is passed as a parameter in the embeddings API</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai --quiet #You can remove '--quiet' to see the installation steps\n",
    "%pip install python-dotenv --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Import Libraries ####\n",
    "import openai #OpenAI python library\n",
    "from openai import OpenAI #OpenAI Client\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings API Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __model__ : The embedding model to use (required)\n",
    "\n",
    "- __input__ : A string/integer or an array of strings/integers for which the embeddings are desired (required)\n",
    "\n",
    "- __encoding format__ : either float or base64\n",
    "\n",
    "- __dimensions__ : length of the embedding vector. [The text-embedding-3-large and text-embedding-3-small models create embedding vectors of length 3,072 and 1,536 respectively. This parameter lets you set lower dimension lengths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try creating an embedding vector for a simple statement - __\"The food was delicious\"__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=client.embeddings.create(\n",
    "  model=\"text-embedding-3-small\",\n",
    "  input=\"The food was delicious\",\n",
    "  encoding_format=\"float\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we chose text-embedding-3-small model, the embedding vector will be of size 1,536."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.019819789, -0.021811483, -0.06169395, -0.038838044, 0.011288293, -0.032474335, -0.007814972, 0.070437975, -0.008889758, -0.04471597, 0.020682048, -0.030701242, 0.005167476, -0.027980879, -0.009915967, -0.009472693, 0.018993964, -0.021738617, -0.017390894, 0.023438843, 0.053872906, -0.0061329617, -0.023001643, -4.990622e-05, -0.0068859193, 0.03733213, -0.00096320896, -0.0014429159, -0.009928111, 0.0076753106, 0.017220872, -0.011616194, 0.023693878, -0.03424743, -0.026985032, -0.022187963, 0.05358144, 0.0347575, 0.034417454, 0.02654783, 0.021520017, 0.060285192, 0.02459257, 0.026474964, 0.049743786, -0.006090456, -0.066988945, 0.03235289, -0.01697798, -0.0130067365, -0.012375223, 0.015532788, -0.0009791485, 0.00421717, 0.0072138202, -0.0030148667, -0.009970617, 0.03633628, 0.034660343, -0.011713349, 0.037696462, -0.005301065, 0.013492516, 0.016237168, 0.008561857, -0.0541158, -0.04933087, 0.008306824, 0.02654783, 0.00553181, 0.0152777545, 0.032765802, -0.060430925, -0.043501522, 0.047800668, -0.007711744, -0.02014769, -0.051055387, 0.013589672, -0.012101973, -0.042748567, 0.019419022, -0.014876987, 0.005914361, 0.02212724, -0.07660737, -0.036506303, 0.02329311, -0.011160776, 0.08739167, 0.0002611063, -0.004954947, 0.03638486, -0.02283162, 0.040805448, 0.0009290526, -0.053727172, 0.019637622, -0.02584345, 0.05052103, 0.0516869, -0.03215858, 0.0063819233, -0.011452244, 0.017135859, 0.004384157, 0.058196343, -0.048383605, -0.022406563, -0.025551984, -0.033154428, -0.022916632, -0.015326332, 0.022673741, 0.011087909, 0.040586848, 0.042311363, -0.10706572, -0.020694192, 0.02773799, -0.01746376, 0.013419649, -0.024398258, -0.054212954, -0.027810857, -0.048286445, -0.0027203632, 0.02606205, -0.030895554, -0.020317713, 0.015678521, -0.0010451842, -0.017609494, -0.014621953, -0.01689297, 0.011786217, -0.03657917, -0.026523542, -0.017718794, 0.01876322, 0.0060358057, -0.016419334, 0.04432735, -0.0037708606, 0.0006466935, -0.05236699, -0.06013946, 0.017038703, 0.016856536, 0.025600562, -0.044643104, 0.014366918, -0.024155369, -0.0060024085, -0.029802551, -0.0050885365, 0.020803493, 0.0006717415, 0.03310585, 0.01852033, -0.033470184, 0.010098134, -0.032280024, 0.0074992157, -0.0042900373, 0.0017457688, -0.038449418, 0.03976102, -0.035680477, -0.023317399, -0.03638486, 0.066794634, 0.009065853, 0.013674683, -0.009065853, -0.021374283, 0.031187022, -0.037647884, -8.055205e-05, -0.026985032, -0.033008695, 0.062714085, 0.006296912, 0.021605028, -0.0068677026, -0.028320923, -0.00034156346, -0.009800594, 0.031575646, 0.05377575, 0.039032355, 0.013346782, -0.0043507596, -0.07932773, -0.0021951145, -0.042214207, -0.016771525, 0.029001014, -0.029438216, 0.01887252, 0.049452316, 0.032522913, 0.041339807, -0.032887246, 0.03142991, -0.03536472, -0.025673429, 0.037137818, -0.0013753622, -0.027300788, 0.06606597, -0.00843434, -0.00902942, 0.016152157, 0.022418708, 0.021058526, -0.018945387, -0.007335265, 0.040465403, 0.037793618, 0.0239732, 0.00077572855, 0.08389406, -0.012290212, 0.00041822548, 0.008525424, -0.02215153, -0.0045025656, 0.011519038, 0.019261144, 0.009946328, 0.044885993, -0.004481313, 0.00015835262, -0.04675624, 0.02283162, -0.002841808, 0.03978531, 0.003946956, 0.035656188, -0.012278068, -0.026936453, 0.013832562, 0.04214134, 0.014634097, 0.04170414, -0.0049336944, -0.013237482, -0.017913107, -0.03631199, 0.005401257, -0.005659327, 0.008476846, -0.04131552, -0.0049124416, -0.004766708, -0.003275973, -0.004414518, 0.017184438, -0.002819037, -0.046076152, 0.029729683, 0.034393165, 0.02654783, -0.0028752054, 0.03815795, -0.004305218, 0.004001606, -0.0356319, 0.0021723437, -0.028709548, -0.027567966, 0.016613647, 0.028102323, 0.0012577126, 0.0020144654, -0.040708292, 0.030215463, -0.026742142, -0.015338477, -0.018228862, -0.03895949, -0.04218992, -0.040805448, 0.037089236, -0.0119866, 0.005701833, -0.01909112, 0.00867723, -0.009241948, -0.014403352, -0.009673078, 0.056301802, 0.002922265, -0.023572434, 0.036457725, 0.0031423839, 0.012405585, 0.047484912, 0.008920119, 0.030385485, 0.018568909, -0.010286373, -0.010887525, 0.0035704768, 0.015010576, -0.039299533, 0.018447462, -0.03140562, 0.049719498, -0.042699985, 0.012363079, 0.044351637, -0.0316728, -0.027009321, -0.038255107, 0.014682675, 0.02399749, -0.01759735, -0.02014769, 0.044375926, -0.010334952, 0.03169709, 0.013868995, 0.024689725, -0.051832635, 0.054164376, -0.011743711, -0.021605028, -0.00669768, 0.013480372, -0.0014087595, 0.007833188, 0.039032355, -0.045056015, -0.003473321, 0.013711116, -0.021058526, 0.062956974, 0.030142596, 0.011695133, -0.030798398, -0.039882466, -0.009169081, 0.022904487, -0.011962311, 0.0435501, 0.04940374, -0.041096915, 0.04029538, -0.025551984, 0.0015332404, -0.0439873, 0.043380078, -0.005553063, -0.020269135, -0.038012218, 0.04867507, -0.023086654, 0.008695447, 0.00048350205, 0.026960744, 0.055864602, 0.004126087, 0.013249626, -0.005049067, -0.0012721341, -0.0020858143, -0.017500194, -0.006491224, -0.014646241, -0.0021298379, -0.037890773, -0.017099425, -0.027543677, 0.016115723, -0.018532474, 0.004484349, 0.0064062127, 0.024313247, 0.040149648, 0.0010451842, 0.0236453, -0.042699985, 0.025139071, -0.044594526, -0.0010937621, -0.019916944, 0.025697717, -0.026523542, 0.04029538, -0.030555509, -0.026960744, 0.033688784, -0.0054467986, 0.023876045, 0.01049283, 0.05474731, 0.0040441114, 0.005908289, 0.03655488, -0.028806703, -0.024871893, -0.022309408, 0.009229803, 0.0037587162, -0.04255425, -0.016941547, -0.033154428, 0.037599307, 0.0005677544, -0.04313719, 0.025916317, -0.0014239402, 0.010322806, -0.031818535, -0.023195954, -0.0019689237, 0.016795814, 0.026134918, -0.023001643, 0.011361159, -0.02538196, 0.0030816614, -0.008659014, 0.03837655, 0.022357985, -0.042481385, -0.01038353, 0.002890386, -0.020572746, -0.062422622, 0.024556136, 0.014124028, -0.012909581, -0.016516492, -0.027519388, 0.020232702, -0.031478487, -0.037429284, 0.0025442683, -0.015629943, -0.011112198, 0.0050126337, 0.020402724, -0.03733213, 0.03728355, -0.0018915025, 0.026523542, 0.0078089, 0.01852033, -0.0060388423, -0.034684632, 0.009266237, -0.041558407, 0.024531847, -0.014682675, 0.0070680864, -0.018641775, -0.02985113, 0.0029465542, 0.019528322, -0.043064322, -0.019601189, -0.0037131743, 0.01977121, 0.003725319, 0.060188036, 0.032668646, -0.02226083, -0.023657445, 0.028296635, -0.008057862, -0.014330485, -0.012053395, -0.054795887, 0.028490948, -0.04189845, 0.0014307714, -0.021799339, 0.00507032, 0.008525424, -0.00431129, 0.0019431165, -0.049282294, -0.050909653, 0.017828094, 0.011245787, 0.0034854654, 0.0008979324, 0.0038437275, 0.026815008, -0.012848859, -0.011154704, -0.011355087, -0.0064487183, -0.042262785, -0.023475278, -0.0035947657, -0.013589672, -0.009132648, -0.049986675, 0.021920783, -0.0036676326, -0.044813126, 0.0049336944, -0.04690198, -0.054650154, 0.01794954, -0.014974142, 0.017548772, 0.05154117, -0.013711116, -0.0057200496, 0.03755073, 0.0479464, -0.028005168, 0.009393754, -0.02467758, 0.038813755, -0.037915062, -0.031599935, -0.0012106528, -0.009770233, 0.018070985, 0.010541407, 0.02337812, 0.022224396, -0.0016030712, -0.03378594, 0.01575139, -0.0015772642, 0.015447777, -0.004305218, 0.025964895, -0.013310349, -0.002362101, 0.016249312, -0.021022093, -0.022297263, 0.021216404, 0.008288607, 0.0006144347, -0.01779166, 0.0158364, 0.025066204, -0.0016212879, -0.03711353, 0.022783043, -0.009169081, -0.021131393, -0.020718481, -0.0024228236, -0.008197523, 0.02017198, 0.03733213, -0.007207748, -0.040902603, 0.00924802, 0.041582696, -0.016091434, -0.01816814, 0.001852033, -0.010863236, -0.020803493, 0.03402883, -0.006369779, 0.026985032, 0.036239125, 0.035218988, 0.013783983, 0.045517508, 0.0318914, -0.054018643, 0.022868054, 0.024337536, 0.08297108, 0.016820103, -0.00030626857, 0.023438843, -0.02562485, 0.028490948, -0.026887875, 0.007062014, 0.02036629, -0.0012827605, 0.046974845, 0.009928111, -0.022042228, -0.03099271, 0.0018277441, -0.016273601, 0.03912951, -0.019589044, 0.007262398, -0.0065155127, -0.036287703, 0.03655488, -0.004815286, 0.011840867, 0.008021428, 0.014767686, 0.012678836, -0.0054376903, -0.03696779, 0.03235289, -0.008057862, -0.0199048, 0.033203006, -0.013650394, -0.015047009, 4.5612953e-05, 0.0022619092, 0.0052373065, -0.020414868, -0.01746376, -0.03419885, -0.011828722, -0.0055014486, -0.022734463, 0.008495063, 0.01667437, 0.009205515, -0.02795659, 0.0057655913, 0.026596408, -0.045056015, 0.007857477, 0.014706964, 0.0055044848, 0.027883723, 0.0053587514, 0.021872206, 0.021532161, -0.024616858, 0.048140712, 0.025503404, 0.017475905, -0.037356418, -0.02215153, -0.010972536, -0.020451302, -0.010207434, 0.003679777, -0.018350307, 0.041874163, 0.034417454, -0.010322806, -0.013905428, -0.025139071, 0.010511046, -0.048407894, -0.028976725, -0.010614274, -0.0054923403, 0.023827467, -0.02226083, -0.010608202, 0.037890773, -0.018326018, 0.014148317, -0.014889131, 0.0008235475, 0.03308156, -0.034636054, -0.008179306, -0.013796127, -0.0032091786, -0.0076692384, -0.021192115, 0.047363468, -0.022248685, 0.023171665, 0.017220872, 0.029073883, -0.015848545, 0.011045404, -0.0051219338, 0.043185767, 0.012253779, -0.030944131, -0.021629317, -0.018180285, 0.0056411102, 0.018423174, -0.07174958, -0.004660444, 0.01233879, 0.007383843, 0.007632805, -0.034903232, 0.01711157, 0.020633468, -0.018678209, 0.03356734, 0.013188904, 0.00083948707, 0.014148317, -0.0045329267, -0.083311126, 0.009339104, -0.024993338, 0.033664495, -0.026183495, -0.040028203, 0.015314188, -0.025236227, -0.03616626, 0.017439472, 0.020779204, 0.01849604, 0.028539525, 0.00082051137, 0.016467914, 0.0041473396, 0.049258005, -0.028466659, -0.0064001405, 0.016528636, -0.013079603, 0.0024835458, -0.0050308504, 0.017585205, -0.046294753, 0.005601641, 0.0021662714, 0.05013241, 0.032110002, 0.031648513, -0.001218243, -0.010480685, -0.040489692, -0.013711116, 0.017560916, 0.04374441, -0.006260479, 0.00797285, -0.011561544, -0.0156178, -0.054844465, -0.0055166297, -0.018447462, -0.016249312, -0.023110943, 0.02014769, -0.006296912, 0.03174567, -0.023936767, -0.030798398, 0.024896182, -0.04330721, 0.007626733, 0.02456828, -0.008300751, 0.0274951, 0.02388819, -0.0008212704, 0.021872206, 0.0015909267, -0.0038255109, -0.010796442, 0.012095901, 0.029292483, -0.024434691, 0.004183773, 0.012605969, 0.021847917, -0.048820805, -0.004997453, 0.003045228, -0.0003557953, -0.006190648, 0.037429284, 0.020839926, 0.010978608, 0.025527693, 0.0018930206, 0.030191174, 0.00023093485, 0.024373969, 0.024046067, -0.019370444, -0.009624499, -0.024604714, -0.003321515, -0.028830992, 0.019977668, -0.026134918, -0.02887957, -0.041412674, -0.013468226, -0.031332754, 0.02399749, -0.00924802, 0.005990264, 0.0026307977, 0.011367232, -0.018617487, -0.010073845, 0.008246101, 0.012982448, -0.013273915, 0.018070985, 0.013213193, 0.047144867, -0.01686868, -0.01654078, 0.05732194, 0.025479116, -0.024604714, 0.0045268545, -0.021762906, -0.01328606, 0.0030224572, 0.060236614, -0.031138442, 0.021568595, -0.020317713, -0.0035886934, 0.014148317, 0.020900648, 0.016905114, -0.005343571, 0.003218287, -0.033688784, 0.029535372, 0.02985113, -0.01865392, -0.010310662, 0.013504661, 0.014706964, -0.01431834, -0.024118934, 0.011585833, 0.021216404, 0.024604714, 0.008999059, -0.00664303, 0.027908012, -0.028296635, 0.014124028, -0.005577352, -0.014026873, -0.023681734, -0.01757306, 0.011604049, 0.009132648, -0.029268194, -0.021422861, -0.0036190546, -0.00019620924, -0.041436963, 0.0007024822, 0.03636057, 0.022139385, 0.008003212, 0.020621324, 0.0026353518, 0.010171001, -0.0787448, -0.04520175, 0.04216563, 0.0072684707, -0.028150901, 0.014986287, -0.014379063, -0.0015393127, -0.015593511, 0.0011552435, -0.004007678, -0.02258873, -0.036506303, -0.03657917, 0.0012136889, 0.018848231, 0.025284804, -0.015581367, 0.0026171352, 0.009509127, -0.042481385, 0.036190547, -0.028150901, -0.041558407, 0.008039645, -0.0037708606, 0.01570281, -0.03262007, 0.029948285, -0.011342943, 0.00012656824, 0.034636054, -0.0052858843, -0.004092689, -0.03006973, -0.023548145, -0.024021778, -0.006570163, -0.021690039, 0.016480058, -0.028903859, -0.011245787, 0.019674055, -0.009624499, -0.016795814, 0.03495181, -0.007086303, 0.00046300824, -0.01794954, 0.03934811, -0.018362451, 0.021046381, -0.024969049, 0.01819243, -0.0067219688, -0.035243277, 0.050423875, 0.01363825, -0.013480372, -0.040829737, 0.032425757, 0.08044503, -0.013407504, 0.03798793, -0.013213193, -0.016795814, -0.011682988, 0.013516805, -0.022139385, -0.019698344, -0.009071926, 0.017184438, -0.024446836, 0.0052919565, 0.013516805, -0.026620697, -0.004208062, 0.009928111, 0.014816264, 0.011148632, -0.038570866, -0.004894225, -0.012739558, -0.029243905, -0.02445898, 0.022710174, 0.016358612, 0.035437588, -0.017403038, 0.008695447, 0.017123714, 0.046246175, -0.016261457, 0.030094018, -0.0027977843, -0.021277126, -0.008531496, 0.0072198925, -0.013613961, -0.035121832, -0.013213193, -0.04167985, -0.000596977, -0.0066308854, 0.008021428, -0.0022953064, -0.011883372, -0.019807644, 0.0433315, -0.04194703, 0.013067459, -0.027567966, -0.02676643, 0.020074824, 0.03330016, -0.002131356, 0.0105171185, 0.03866802, -0.01491342, -0.022892343, -0.00878653, -0.013966151, 0.018908953, 0.007717816, 0.019759066, -0.026985032, -0.003956064, 0.035510454, 0.013711116, -0.029389638, -0.02049988, 0.024859749, -0.012302357, -0.008161089, 0.0030103126, 0.021520017, 0.0002396637, 0.0029480723, 0.025114782, 0.013917573, 0.00854364, -0.03978531, -0.004447915, 0.041777007, -0.024228236, -0.04678053, -0.004818322, 0.024046067, 0.0056198575, -0.02399749, -0.0017655035, -0.003910522, -0.00854364, -0.0097520165, -0.0018155995, -0.007887839, -0.033251584, -0.022491574, 0.006825197, 0.019030398, 0.009727728, 0.028199479, -0.009071926, -0.0060934923, -0.032522913, 0.016443623, -0.015532788, 0.02936535, -0.0048547555, 0.045736108, -0.03912951, 0.0018930206, 0.005301065, -0.008701519, -0.011962311, 0.032547202, 0.031867113, -0.031624224, -0.031259887, -0.058779277, 0.010146712, -0.020633468, 0.009132648, 0.0034034902, 0.03536472, 0.026450675, -0.0016167337, -0.019078976, 0.013261771, 0.018471751, -0.024155369, 0.019722633, -0.05732194, 0.01781595, -0.005158367, 0.012302357, -0.024337536, 0.03096842, -0.024629002, 0.038109373, -0.012618113, -0.03976102, 0.02036629, 0.013116037, -0.069806464, 0.013735405, -0.012223418, 0.015447777, -0.0077056717, -0.008416124, 0.030191174, 0.013273915, 0.030118307, 0.010565696, 0.029195327, -0.040465403, -0.033275872, -0.004444879, -0.015909268, -0.017609494, 0.008440413, 0.023390265, 0.0048092133, 0.0012660619, 0.040684003, -0.0038771247, 0.01770665, -0.020014102, -0.052949928, -0.0194676, -0.009891678, -0.03609339, 0.028005168, 0.015775679, 0.0018429246, 0.02841808, 0.019916944, 0.0014573374, 0.03636057, 0.006135998, 0.012836714, 0.015217031, -0.029438216, 0.021459294, -0.018581053, 0.025211938, 0.025527693, 0.043914434, 0.024386114, -0.020269135, -0.010395674, 0.027179344, 0.012618113, 0.01841103, 0.033421606, 0.047387756, -0.00035181036, 0.002184488, 0.018326018, -0.021738617, 0.006260479, -0.02003839, 0.0081914505, -1.3994614e-05, 0.008361474, -0.018447462, 0.0056684352, -0.020050535, 0.026110629, -0.055816025, -0.011355087, -0.0017154076, 0.013164615, 0.0104624685, -0.0077603217, -0.00062468165, 0.005969011, 0.025794873, -0.022163674, 0.0069952197, 0.026863586, 0.021920783, -0.004444879, -0.029875418, 0.022892343, 0.0048669, -0.03330016, -0.000760548, 0.09807881, -0.0063090567, 0.0065337294, 0.02076706, 0.009715583, -0.012095901, -0.010073845, 0.005956867, 0.017670216, -0.0037921134, 0.022734463, -0.021957217, 0.008877614, 0.0030558545, 0.04216563, 0.022248685, -0.024762591, -0.015678521, 0.023681734, -0.014039017, 0.033470184, 0.031454198, -0.0011097017, -0.019273289, -0.025576273, 0.002741616, -0.010061701, -0.04918514, -0.018641775, 0.030701242, 0.04056256, -0.007298832, 0.009308743, 0.009667005, 0.022528008, -0.0102438675, 0.009126576, -0.008015356, -0.03281438, -0.0060266973, -0.006740186, 0.033397317, 0.0013381698, 0.023038076, 0.015289899, 0.023742456, 0.0012569536, -0.017500194, -0.014379063, -0.011500821, 0.018921098, -0.022115096, -0.016589358, -0.018508185, -0.020451302, -0.015034865, 0.014549086, -0.06407427, 0.00629084, 0.0106264185, -0.0104624685, -0.012508813, 0.005877928, -0.006242262, 0.026110629, 0.013346782, -0.031454198, -0.0011605568, 0.020997804, 0.020135546, 0.016807958, 0.021544306, -0.01008599, 0.00020342002, 0.006169395, 0.011106126, 0.021483583, -0.0025564127, -0.010104206, -0.016067145, -0.020378435, 0.037162106, 0.023936767, 0.004244495, -0.0018444427, -0.019601189, -0.03281438, 0.010705358, -0.015994279, -0.009563777, 0.005911325, 0.021082815, -0.0006341695, 0.035267565, 0.020196268, 0.03910522, -0.007924273, 0.014051162, -0.043598678, -0.0069648586, 0.015775679, -0.01570281, 0.0039955336, 0.04235994, -0.0023028967, -0.01781595, -0.03774504, -0.023936767, -0.010638563, -0.04255425, 0.013164615, -0.006163323, -0.0072927596, 0.03028833, 0.009521271, 0.024446836, -0.041995607, 0.005525738, -0.011573688, -0.015909268, 0.004751527, 0.011160776, 0.0037860412, 0.026110629, 0.041145492, -0.015994279, 0.030094018, 0.046877686, 0.025479116, -0.010268156, 0.013298204, -0.01838674, -0.011604049, -0.015848545, 0.009964544, -0.004359868, 0.0011544845, -0.007055942, 0.0033761652, -0.001471, -0.011136487, 0.08316539, -0.031794246, 0.02283162, 0.03281438, 0.004241459, -0.031332754, -0.015423488, 0.011597977, -1.6093807e-05, 0.0088472525, 0.01570281, 0.014852697, -0.03351876, 0.020524168, 0.0041078697, 0.046246175, 0.00629084, 0.002210295, -0.04452166, 0.012861003, -0.0026520505, 0.013783983, 0.03281438, 0.014391207, 0.02562485, -0.02226083, -0.005483232, -0.021228548, -0.00074157224, 0.016722947, -0.022430852, 0.0018110453, 0.0037647884, -0.010359241, 0.009108359, -0.03395596, 0.01808313, 0.0030300475, -0.021252837, 0.006296912, -6.636768e-05, 0.009509127, -0.017220872, 0.027762279, -0.016965836, -0.024046067, -0.033615917, -0.033591628, -0.0148648415, 0.023353832, 0.021058526, -0.0016440589, 0.017633783, -0.019406877, 0.052998506, -0.015071298, 0.03026404, -0.0056532547, -0.014634097, -0.03750215, -0.005662363, -0.023936767, 0.029171038, 0.019856222, 0.023110943, 0.0077481773, -0.0012599897, 0.02039058, 0.0026171352, -0.010013123, 0.04194703, -0.03398025, 0.0021283198, -0.004305218, 0.06494867, -0.007505288, 0.050472453, -0.0029161929, -0.011865156, -0.0124602355, -0.012023034, 0.005373932, -0.038595155, -0.013031025, -0.010693214, 0.0023939803, -0.028102323, -0.023633156, -0.0037162104, 0.02586774, 0.018908953, 0.01008599, -0.046683375, -0.03334874, -0.0047545633, -0.0048577916, -0.01865392, 0.01030459, 0.0035158265, -0.029996863, 0.0043720123, -0.039250955, 0.0059234696, -0.0055348463, 0.022758754, -0.015204887, 0.013954006, -0.009873461, -0.026474964, -0.01456123, -0.008403979, 0.020402724, -0.003476357, 0.01228414, -0.0066308854, -0.00053891126, -0.0028964581, -0.028928148, -0.067669034, -0.04170414, 0.010213506, -0.0024228236, 0.03053122, 0.0156178, 0.011215426, 0.01420904, 0.0130067365, 0.010644635, 0.0052980287, 0.007711744, 0.003752644, 0.015678521, -0.072138205, -0.031648513, 0.01827744, 0.009618427, 0.0066005243, 0.0197955, -0.018738931, -0.024301102, 0.01876322, 0.004390229, -0.014257618, 0.005425546, 0.0016607575, 0.024920471, 0.0064001405, -0.032717224, -0.004872972, -0.022066519, -0.0010808586, -0.0009525826, -0.009290527, 0.020706337, 0.03395596, 0.037380707, -0.03976102, 0.017961685, 0.014682675, -0.01304317, -0.0037465717, 0.00014051542, 0.02109496, 0.041048337, 0.023365976, 0.0023408483, 0.0041777007, -0.0014011692, 0.02096137, 0.027810857, -0.0024698833, 0.03696779, 0.017172294, -0.015253466, 0.00038843357, 0.0073413374, 0.015520643, -0.004390229, 0.010504974, -0.0076753106, -0.009575921, -0.026256364, -0.006321201, -0.07437279, 0.010474613, -0.011792289, 0.002258873, -0.019163987, 0.013103892, -0.03776933, -0.030215463, 0.0038619442, 0.026256364, 0.0021647534, -0.007414204, -0.024070356, 0.017767372, -0.0017624674, -0.024847602, -0.015654232, -0.030725531, 0.018131707, -0.016941547, 0.0019613332, 0.017730938, -0.011938022, 0.025794873, 0.012739558, 0.012083757, -0.018836087, 0.0036828131, -0.0063090567, 0.009333032, 0.018556764, -0.0089322645, 0.050180987, -0.055330247, -0.013358926, 0.01003134, -0.0045754323, -0.043282922, 0.012605969, -0.014658386, -0.015787823, 0.038643733, -0.040465403, 0.03704066, 0.012180912, -0.009478766, -0.00573523, 0.033275872, -0.0237546, -0.008282535, -0.0033306233, 0.016346468, -0.046464775, 0.00044251443, 0.019710489, 0.016225023, 0.021835772, 0.038303684, -0.007814972, 0.022953065, 0.04454595, 0.02215153, 0.017900962, 0.033834517, -0.016067145]\n"
     ]
    }
   ],
   "source": [
    "print(embeddings.data[0].embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings Response Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create embeddings for 3 strings - __\"The food was delicious\"__, __\"The ambience was nice\"__, __\"The service was ordinary\"__\n",
    "\n",
    "We'll set the size of the embeddings vector to size 10, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=client.embeddings.create(\n",
    "  model=\"text-embedding-3-small\",\n",
    "  input=[\"The food was delicious\",\"The ambience was nice\",\"The service was ordinary\"],\n",
    "  encoding_format=\"float\",\n",
    "  dimensions=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embeddings.model_dump_json(indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Assets/Images/Embedding Response Object.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Text Search\n",
    "- Clustering\n",
    "- For downstream ML models\n",
    "- Recommendation Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue with our example of the three sentences - __\"The food was delicious\"__, __\"The ambience was nice\"__, __\"The service was ordinary\"__\n",
    "\n",
    "Now, just to demonstrate the idea of how text search is performed, let's search for __\"food\"__ amongst the three statements\n",
    "\n",
    "To achieve this, we will first create embeddings for the search string i.e. __\"food\"__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_q=client.embeddings.create(\n",
    "  model=\"text-embedding-3-small\",\n",
    "  input=\"food\",\n",
    "  encoding_format=\"float\",\n",
    "  dimensions=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=embeddings_q.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.012315562,\n",
       " -0.16567738,\n",
       " -0.069231726,\n",
       " -0.10728083,\n",
       " 0.4480219,\n",
       " -0.61836094,\n",
       " 0.29532152,\n",
       " 0.4434862,\n",
       " -0.24505134,\n",
       " -0.17046502]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's recall the embeddings of the three statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1=embeddings.data[0].embedding #\"The food was delicious\"\n",
    "d2=embeddings.data[1].embedding #\"The ambience was nice\"\n",
    "d3=embeddings.data[2].embedding #\"The service was ordinary\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measuring Similarity\n",
    "\n",
    "__Cosine Similarity__: This method measures the cosine of the angle between the two embeddings. It ranges from -1 to 1, where 1 means the embeddings are identical, 0 means they are orthogonal, and -1 means they are diametrically opposed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Assets/Images/cosine similarity.png\" width=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://storage.googleapis.com/lds-media/images/cosine-similarity-vectors.original.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we code this calculation, there's a simpler way.\n",
    "\n",
    "Let's install the __scikit learn__ library and import the __cosine similarity__ function\n",
    "\n",
    "_scikit-learn is a popular open-source machine learning library for the Python programming language. It provides simple and efficient tools for data mining and data analysis, built on top of other Python libraries such as NumPy, SciPy, and matplotlib_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-learn --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity #for calculating similarities between embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate the similarity scores between each of the three input vectors and our query vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity between the string 1 and the query is 0.6332541953557046\n"
     ]
    }
   ],
   "source": [
    "print(f\"The similarity between the string 1 and the query is {cosine_similarity([query],[d1])[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity between the string 2 and the query is 0.5118057548747722\n"
     ]
    }
   ],
   "source": [
    "print(f\"The similarity between the string 2 and the query is {cosine_similarity([query],[d2])[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The similarity between the string 3 and the query is 0.2872144907165794\n"
     ]
    }
   ],
   "source": [
    "print(f\"The similarity between the string 3 and the query is {cosine_similarity([query],[d3])[0][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the similarity score between the statement __\"The food was delicious\"__ and the query __\"food\"__ is the highest.\n",
    "\n",
    "Great, this cosine similarity seems to work. Now let's see how to implement this at a slightly bigger scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Search at Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Medium__ is a popular online publishing platform where users can read, write, and interact with a wide range of articles and blog posts covering various topics such as technology, entrepreneurship, politics, culture, and more.\n",
    "\n",
    "We will use this dataset which has __1300+ Towards DataScience Medium Articles__ from Kaggle and search the article headlines for closest matches.\n",
    "\n",
    "Data Source - https://www.kaggle.com/datasets/meruvulikith/1300-towards-datascience-medium-articles-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv(\"../Assets/Data/medium.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Beginner’s Guide to Word Embedding with Gens...</td>\n",
       "      <td>1. Introduction of Word2vec\\n\\nWord2vec is one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hands-on Graph Neural Networks with PyTorch &amp; ...</td>\n",
       "      <td>In my last article, I introduced the concept o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to Use ggplot2 in Python</td>\n",
       "      <td>Introduction\\n\\nThanks to its strict implement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Databricks: How to Save Data Frames as CSV Fil...</td>\n",
       "      <td>Photo credit to Mika Baumeister from Unsplash\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Step-by-Step Implementation of Gradient Desc...</td>\n",
       "      <td>A Step-by-Step Implementation of Gradient Desc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  A Beginner’s Guide to Word Embedding with Gens...   \n",
       "1  Hands-on Graph Neural Networks with PyTorch & ...   \n",
       "2                       How to Use ggplot2 in Python   \n",
       "3  Databricks: How to Save Data Frames as CSV Fil...   \n",
       "4  A Step-by-Step Implementation of Gradient Desc...   \n",
       "\n",
       "                                                Text  \n",
       "0  1. Introduction of Word2vec\\n\\nWord2vec is one...  \n",
       "1  In my last article, I introduced the concept o...  \n",
       "2  Introduction\\n\\nThanks to its strict implement...  \n",
       "3  Photo credit to Mika Baumeister from Unsplash\\...  \n",
       "4  A Step-by-Step Implementation of Gradient Desc...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset has just two columns - \n",
    "\n",
    "- The title of the article\n",
    "- The text of the article\n",
    "\n",
    "We'll use the title of the article for this demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1391, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of embeddings takes time. The data has 1391 articles, but for our demonstration we shall use 100 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trunc_data=data.iloc[0:100,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trunc_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now define a function that replaces new line characters with space and creates embeddings for an input string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1389860027.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  trunc_data['embedding'] = trunc_data['Title'].apply(lambda x: get_embedding(x, model='text-embedding-3-small'))\n"
     ]
    }
   ],
   "source": [
    "trunc_data['embedding'] = trunc_data['Title'].apply(lambda x: get_embedding(x, model='text-embedding-3-small'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Beginner’s Guide to Word Embedding with Gens...</td>\n",
       "      <td>1. Introduction of Word2vec\\n\\nWord2vec is one...</td>\n",
       "      <td>[-0.024416513741016388, 0.019436374306678772, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hands-on Graph Neural Networks with PyTorch &amp; ...</td>\n",
       "      <td>In my last article, I introduced the concept o...</td>\n",
       "      <td>[-0.011600558646023273, -0.02944890409708023, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to Use ggplot2 in Python</td>\n",
       "      <td>Introduction\\n\\nThanks to its strict implement...</td>\n",
       "      <td>[-0.0054690418764948845, -0.024078190326690674...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Databricks: How to Save Data Frames as CSV Fil...</td>\n",
       "      <td>Photo credit to Mika Baumeister from Unsplash\\...</td>\n",
       "      <td>[-0.003941336181014776, -0.022551342844963074,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Step-by-Step Implementation of Gradient Desc...</td>\n",
       "      <td>A Step-by-Step Implementation of Gradient Desc...</td>\n",
       "      <td>[-0.0020211779046803713, -0.000974284252151846...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  A Beginner’s Guide to Word Embedding with Gens...   \n",
       "1  Hands-on Graph Neural Networks with PyTorch & ...   \n",
       "2                       How to Use ggplot2 in Python   \n",
       "3  Databricks: How to Save Data Frames as CSV Fil...   \n",
       "4  A Step-by-Step Implementation of Gradient Desc...   \n",
       "\n",
       "                                                Text  \\\n",
       "0  1. Introduction of Word2vec\\n\\nWord2vec is one...   \n",
       "1  In my last article, I introduced the concept o...   \n",
       "2  Introduction\\n\\nThanks to its strict implement...   \n",
       "3  Photo credit to Mika Baumeister from Unsplash\\...   \n",
       "4  A Step-by-Step Implementation of Gradient Desc...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.024416513741016388, 0.019436374306678772, ...  \n",
       "1  [-0.011600558646023273, -0.02944890409708023, ...  \n",
       "2  [-0.0054690418764948845, -0.024078190326690674...  \n",
       "3  [-0.003941336181014776, -0.022551342844963074,...  \n",
       "4  [-0.0020211779046803713, -0.000974284252151846...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trunc_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have another column in our data which stores the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try searching articles related to __\"Deep Learning\"__ from the set. \n",
    "\n",
    "To do this, we'll first create an embedding of the search string and then find the cosine distance of the search string embedding from all the titles in the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_string=\"Deep Learning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_embedding=get_embedding(search_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll find the cosine similarity and store it in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n",
      "/var/folders/kz/0m0zvdwn54798h3cfz47bcjw0000gn/T/ipykernel_53470/1347396313.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))\n"
     ]
    }
   ],
   "source": [
    "trunc_data['relevance'] = trunc_data.embedding.apply(lambda x: float(cosine_similarity([search_embedding],[x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>embedding</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Beginner’s Guide to Word Embedding with Gensim Word2Vec Model</td>\n",
       "      <td>1. Introduction of Word2vec\\n\\nWord2vec is one of the most popular technique to learn word embed...</td>\n",
       "      <td>[-0.024416513741016388, 0.019436374306678772, 0.023113839328289032, -0.01980527490377426, -0.044...</td>\n",
       "      <td>0.300155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hands-on Graph Neural Networks with PyTorch &amp; PyTorch Geometric</td>\n",
       "      <td>In my last article, I introduced the concept of Graph Neural Network (GNN) and some recent advan...</td>\n",
       "      <td>[-0.011600558646023273, -0.02944890409708023, 0.004553031641989946, -0.03210508078336716, 0.0400...</td>\n",
       "      <td>0.344641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How to Use ggplot2 in Python</td>\n",
       "      <td>Introduction\\n\\nThanks to its strict implementation of the grammar of graphics, ggplot2 provides...</td>\n",
       "      <td>[-0.0054690418764948845, -0.024078190326690674, 0.01770878955721855, -0.012851991690695286, -0.0...</td>\n",
       "      <td>0.109014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Databricks: How to Save Data Frames as CSV Files on Your Local Computer</td>\n",
       "      <td>Photo credit to Mika Baumeister from Unsplash\\n\\nWhen I work on Python projects dealing with lar...</td>\n",
       "      <td>[-0.003941336181014776, -0.022551342844963074, 0.06862198561429977, -0.04217821732163429, 0.0360...</td>\n",
       "      <td>0.169241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Step-by-Step Implementation of Gradient Descent and Backpropagation</td>\n",
       "      <td>A Step-by-Step Implementation of Gradient Descent and Backpropagation\\n\\nThe original intention ...</td>\n",
       "      <td>[-0.0020211779046803713, -0.0009742842521518469, 0.01972859725356102, -0.01853516511619091, 0.01...</td>\n",
       "      <td>0.388754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Data Scientist’s toolkit — How to gather data from different sources</td>\n",
       "      <td>Data Scientist’s toolkit — How to gather data from different sources\\n\\nPhoto by Jakob Owens on ...</td>\n",
       "      <td>[-0.026935778558254242, -0.02546488121151924, 0.022867832332849503, -0.014329741708934307, 0.045...</td>\n",
       "      <td>0.313273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Deep Learning on a Budget</td>\n",
       "      <td>Introduction\\n\\nWhy?\\n\\nThere are many articles and courses dedicated to the latest ML/AI resear...</td>\n",
       "      <td>[-0.016848241910338402, -0.045139651745557785, -0.008332818746566772, -0.010773622430860996, 0.0...</td>\n",
       "      <td>0.719206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Generating Startup names with Markov Chains</td>\n",
       "      <td>Generating Startup names with Markov Chains\\n\\nThe most interesting applications of Machine Lear...</td>\n",
       "      <td>[0.013092967681586742, -0.0023525876458734274, 0.03218775615096092, -0.037528958171606064, -0.03...</td>\n",
       "      <td>0.165855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>A Recipe for using Open Source Machine Learning models</td>\n",
       "      <td>A Recipe for using Open Source Machine Learning models\\n\\nPhoto by Luca Bravo on Unsplash\\n\\nMac...</td>\n",
       "      <td>[-0.017321426421403885, -0.021059678867459297, 0.026052551344037056, -0.0624237060546875, 0.0059...</td>\n",
       "      <td>0.387291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>How to Choose Between Multiple Models</td>\n",
       "      <td>How to Choose Between Multiple Models\\n\\nIn a previous article we discussed the concepts of unde...</td>\n",
       "      <td>[0.004774938337504864, -0.0009390711784362793, 0.01962406001985073, -0.04452114924788475, -0.009...</td>\n",
       "      <td>0.233194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      Title  \\\n",
       "0           A Beginner’s Guide to Word Embedding with Gensim Word2Vec Model   \n",
       "1           Hands-on Graph Neural Networks with PyTorch & PyTorch Geometric   \n",
       "2                                              How to Use ggplot2 in Python   \n",
       "3   Databricks: How to Save Data Frames as CSV Files on Your Local Computer   \n",
       "4     A Step-by-Step Implementation of Gradient Descent and Backpropagation   \n",
       "..                                                                      ...   \n",
       "95     Data Scientist’s toolkit — How to gather data from different sources   \n",
       "96                                                Deep Learning on a Budget   \n",
       "97                              Generating Startup names with Markov Chains   \n",
       "98                   A Recipe for using Open Source Machine Learning models   \n",
       "99                                    How to Choose Between Multiple Models   \n",
       "\n",
       "                                                                                                   Text  \\\n",
       "0   1. Introduction of Word2vec\\n\\nWord2vec is one of the most popular technique to learn word embed...   \n",
       "1   In my last article, I introduced the concept of Graph Neural Network (GNN) and some recent advan...   \n",
       "2   Introduction\\n\\nThanks to its strict implementation of the grammar of graphics, ggplot2 provides...   \n",
       "3   Photo credit to Mika Baumeister from Unsplash\\n\\nWhen I work on Python projects dealing with lar...   \n",
       "4   A Step-by-Step Implementation of Gradient Descent and Backpropagation\\n\\nThe original intention ...   \n",
       "..                                                                                                  ...   \n",
       "95  Data Scientist’s toolkit — How to gather data from different sources\\n\\nPhoto by Jakob Owens on ...   \n",
       "96  Introduction\\n\\nWhy?\\n\\nThere are many articles and courses dedicated to the latest ML/AI resear...   \n",
       "97  Generating Startup names with Markov Chains\\n\\nThe most interesting applications of Machine Lear...   \n",
       "98  A Recipe for using Open Source Machine Learning models\\n\\nPhoto by Luca Bravo on Unsplash\\n\\nMac...   \n",
       "99  How to Choose Between Multiple Models\\n\\nIn a previous article we discussed the concepts of unde...   \n",
       "\n",
       "                                                                                              embedding  \\\n",
       "0   [-0.024416513741016388, 0.019436374306678772, 0.023113839328289032, -0.01980527490377426, -0.044...   \n",
       "1   [-0.011600558646023273, -0.02944890409708023, 0.004553031641989946, -0.03210508078336716, 0.0400...   \n",
       "2   [-0.0054690418764948845, -0.024078190326690674, 0.01770878955721855, -0.012851991690695286, -0.0...   \n",
       "3   [-0.003941336181014776, -0.022551342844963074, 0.06862198561429977, -0.04217821732163429, 0.0360...   \n",
       "4   [-0.0020211779046803713, -0.0009742842521518469, 0.01972859725356102, -0.01853516511619091, 0.01...   \n",
       "..                                                                                                  ...   \n",
       "95  [-0.026935778558254242, -0.02546488121151924, 0.022867832332849503, -0.014329741708934307, 0.045...   \n",
       "96  [-0.016848241910338402, -0.045139651745557785, -0.008332818746566772, -0.010773622430860996, 0.0...   \n",
       "97  [0.013092967681586742, -0.0023525876458734274, 0.03218775615096092, -0.037528958171606064, -0.03...   \n",
       "98  [-0.017321426421403885, -0.021059678867459297, 0.026052551344037056, -0.0624237060546875, 0.0059...   \n",
       "99  [0.004774938337504864, -0.0009390711784362793, 0.01962406001985073, -0.04452114924788475, -0.009...   \n",
       "\n",
       "    relevance  \n",
       "0    0.300155  \n",
       "1    0.344641  \n",
       "2    0.109014  \n",
       "3    0.169241  \n",
       "4    0.388754  \n",
       "..        ...  \n",
       "95   0.313273  \n",
       "96   0.719206  \n",
       "97   0.165855  \n",
       "98   0.387291  \n",
       "99   0.233194  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trunc_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can sort the dataset by this score and see the top 10 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                        Title  \\\n",
      "96                                                  Deep Learning on a Budget   \n",
      "79                            Applied AI: Going From Concept to ML Components   \n",
      "73                        Transfer Learning Intuition for Text Classification   \n",
      "54                                        Reinforcement Learning Introduction   \n",
      "80                                     Wild Wide AI: responsible data science   \n",
      "26                          Why Machine Learning Models Degrade In Production   \n",
      "29                 An Introduction to Recurrent Neural Networks for Beginners   \n",
      "9                                   What if AI model understanding were easy?   \n",
      "68  Getting Started with Google BigQuery’s Machine Learning — Titanic Dataset   \n",
      "69                  Review: DeepPose — Cascade of CNN (Human Pose Estimation)   \n",
      "\n",
      "    relevance  \n",
      "96   0.719206  \n",
      "79   0.482872  \n",
      "73   0.478084  \n",
      "54   0.470448  \n",
      "80   0.445177  \n",
      "26   0.437601  \n",
      "29   0.424425  \n",
      "9    0.422850  \n",
      "68   0.416430  \n",
      "69   0.412199  \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', 150)\n",
    "print(trunc_data.sort_values(by=\"relevance\",ascending=False).iloc[0:10,:][[\"Title\",\"relevance\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! We're at the end of Day 3!\n",
    "\n",
    "Hopefully, now we are fairly confident around using OpenAI embeddings. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Assets/Images/That’s all for the day!.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../Assets/Images/profile.png\" width=100> \n",
    "\n",
    "#### Hi! I'm Abhinav! A data science and AI professional with over 15 years in the industry. Passionate about AI advancements, I constantly explore emerging technologies to push the boundaries and create positive impacts in the world. Let’s build the future, together!\n",
    "\n",
    "<span style=\"font-size: 20px; color: orange\"><b>Connect with me!</b></span>\n",
    "\n",
    "\n",
    "[![GitHub followers](https://img.shields.io/badge/Github-000000?style=for-the-badge&logo=github&logoColor=black&color=orange)](https://github.com/abhinav-kimothi)\n",
    "[![LinkedIn](https://img.shields.io/badge/LinkedIn-000000?style=for-the-badge&logo=linkedin&logoColor=orange&color=black)](https://www.linkedin.com/comm/mynetwork/discovery-see-all?usecase=PEOPLE_FOLLOWS&followMember=abhinav-kimothi)\n",
    "[![Medium](https://img.shields.io/badge/Medium-000000?style=for-the-badge&logo=medium&logoColor=black&color=orange)](https://medium.com/@abhinavkimothi)\n",
    "[![Insta](https://img.shields.io/badge/Instagram-000000?style=for-the-badge&logo=instagram&logoColor=orange&color=black)](https://www.instagram.com/akaiworks/)\n",
    "[![Mail](https://img.shields.io/badge/email-000000?style=for-the-badge&logo=gmail&logoColor=black&color=orange)](mailto:abhinav.kimothi.ds@gmail.com)\n",
    "[![X](https://img.shields.io/badge/Follow-000000?style=for-the-badge&logo=X&logoColor=orange&color=black)](https://twitter.com/abhinav_kimothi)\n",
    "[![Linktree](https://img.shields.io/badge/Linktree-000000?style=for-the-badge&logo=linktree&logoColor=black&color=orange)](https://linktr.ee/abhinavkimothi)\n",
    "[![Gumroad](https://img.shields.io/badge/Gumroad-000000?style=for-the-badge&logo=gumroad&logoColor=orange&color=black)](https://abhinavkimothi.gumroad.com/)\n",
    "\n",
    "\n",
    "<span style=\"font-size: 20px; color: orange\"><b>You can also book a time-slot with me</b></span>\n",
    "\n",
    "[![Static Badge](https://img.shields.io/badge/Free%20Virtual%20Coffee%20(15%20min)-000000?style=for-the-badge&logo=googlecalendar&logoColor=black&color=blue)](https://topmate.io/abhinav_kimothi/544386)\n",
    "[![Static Badge](https://img.shields.io/badge/Resume%20Review%20(DS/AI/ML)%20(30%20min)-000000?style=for-the-badge&logo=googlecalendar&logoColor=blue&color=black)](https://topmate.io/abhinav_kimothi/544382)\n",
    "[![Static Badge](https://img.shields.io/badge/AIML%20Learning%20Path%20(30%20min)-000000?style=for-the-badge&logo=googlecalendar&logoColor=black&color=blue)](https://topmate.io/abhinav_kimothi/544380)\n",
    "[![Static Badge](https://img.shields.io/badge/Generative%20AI%20Consulting%20(60%20min)-000000?style=for-the-badge&logo=googlecalendar&logoColor=blue&color=black)](https://topmate.io/abhinav_kimothi/544379)\n",
    "\n",
    "\n",
    "<span style=\"font-size: 20px; color: orange\"><b>Also, read my ebooks for more on Generative AI!</b></span>\n",
    "\n",
    "\n",
    "\n",
    "<a href=\"https://abhinavkimothi.gumroad.com/l/GenAILLM\">\n",
    "    <img src=\"https://public-files.gumroad.com/jsdnnne2gnhu61f6hrdprwx2255i\" width=150>\n",
    "</a><a href=\"abhinavkimothi.gumroad.com/l/RAG\">\n",
    "    <img src=\"https://public-files.gumroad.com/v17k9tp2fnbbtg8iwoxt4m3xgivq\" width=150>\n",
    "</a><a href=\"abhinavkimothi.gumroad.com/l/GenAITaxonomy\">\n",
    "    <img src=\"https://public-files.gumroad.com/a730ysxb7a928bb5xkz6fuqabaqp\" width=150>\n",
    "</a>\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
